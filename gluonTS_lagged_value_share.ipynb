{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gluonTS_lagged_value_share",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqSOsAqoi8LBZE/cpH/gbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/GluonTS/blob/master/gluonTS_lagged_value_share.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtkVPqoH9Rfy",
        "colab_type": "text"
      },
      "source": [
        "### 환경 구현 @ CPU Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfXmDXu9b8y",
        "colab_type": "text"
      },
      "source": [
        "MXNET 설치 \n",
        "- GluonTS는 Amazon이 2019년 공개한 Tool로서 MXNET을 backbone으로 사용\n",
        "  - https://aws.amazon.com/blogs/machine-learning/creating-neural-time-series-models-with-gluon-time-series/\n",
        "\n",
        "- 어떤 버전의 MXNET을 설치해야 하는 지는 아래 링크 참고\n",
        "  - https://mxnet.apache.org/get_started/?platform=linux&language=python&processor=gpu&environ=pip&"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpYiCxWFwrdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrgwGyjH-_1K",
        "colab_type": "text"
      },
      "source": [
        "GluonTS를 설치함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O45K03dixX4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gluonts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgAwO-8qksBN",
        "colab_type": "text"
      },
      "source": [
        "### lag.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWnI8WWQMGLy",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/awslabs/gluon-ts/blob/master/src/gluonts/time_feature/lag.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cFmj82pidzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.tseries.frequencies import to_offset\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCO8rzIcipX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _make_lags(middle: int, delta: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a set of lags around a middle point including +/- delta\n",
        "    \"\"\"\n",
        "    return np.arange(middle - delta, middle + delta + 1).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBjk7y5Hizob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lags are target values at the same `season` (+/- delta) but in the previous cycle.\n",
        "def _make_lags_for_minute(multiple, num_cycles=3):\n",
        "    # We use previous ``num_cycles`` hours to generate lags\n",
        "    return [\n",
        "        _make_lags(k * 60 // multiple, 2) for k in range(1, num_cycles + 1)\n",
        "    ]\n",
        "\n",
        "def _make_lags_for_hour(multiple, num_cycles=7):\n",
        "    # We use previous ``num_cycles`` days to generate lags\n",
        "    return [\n",
        "        _make_lags(k * 24 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ]\n",
        "\n",
        "def _make_lags_for_day(multiple, num_cycles=4):\n",
        "    # We use previous ``num_cycles`` weeks to generate lags\n",
        "    # We use the last month (in addition to 4 weeks) to generate lag.\n",
        "    return [\n",
        "        _make_lags(k * 7 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ] + [_make_lags(30 // multiple, 1)]\n",
        "\n",
        "def _make_lags_for_week(multiple, num_cycles=3):\n",
        "    # We use previous ``num_cycles`` years to generate lags\n",
        "    # Additionally, we use previous 4, 8, 12 weeks\n",
        "    return [\n",
        "        _make_lags(k * 52 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ] + [[4 // multiple, 8 // multiple, 12 // multiple]]\n",
        "\n",
        "def _make_lags_for_month(multiple, num_cycles=3):\n",
        "    # We use previous ``num_cycles`` years to generate lags\n",
        "    return [\n",
        "        _make_lags(k * 12 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66VRD7hi_Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_str = '5min'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffrJnBNzjCqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiple, granularity = get_granularity(freq_str)\n",
        "offset = to_offset(freq_str)# pandas 함수, to_offset('5min') -> <5 * Minutes>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aegiHu5GjEpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lags = (\n",
        "            _make_lags_for_minute(offset.n)\n",
        "            + _make_lags_for_hour(offset.n / 60.0)\n",
        "            + _make_lags_for_day(offset.n / (60.0 * 24))\n",
        "            + _make_lags_for_week(offset.n / (60.0 * 24 * 7))\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xetgsjpzjI7d",
        "colab_type": "code",
        "outputId": "78c5bd1f-2857-423f-fdec-3ee866a809d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "lags"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 11, 12, 13, 14],\n",
              " [22, 23, 24, 25, 26],\n",
              " [34, 35, 36, 37, 38],\n",
              " [287.0, 288.0, 289.0],\n",
              " [575.0, 576.0, 577.0],\n",
              " [863.0, 864.0, 865.0],\n",
              " [1151.0, 1152.0, 1153.0],\n",
              " [1439.0, 1440.0, 1441.0],\n",
              " [1727.0, 1728.0, 1729.0],\n",
              " [2015.0, 2016.0, 2017.0],\n",
              " [2015.0, 2016.0, 2017.0],\n",
              " [4031.0, 4032.0, 4033.0],\n",
              " [6047.0, 6048.0, 6049.0],\n",
              " [8063.0, 8064.0, 8065.0],\n",
              " [8639.0, 8640.0, 8641.0],\n",
              " [104831.0, 104832.0, 104833.0],\n",
              " [209663.0, 209664.0, 209665.0],\n",
              " [314495.0, 314496.0, 314497.0],\n",
              " [8064.0, 16128.0, 24192.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4wgelnik90E",
        "colab_type": "text"
      },
      "source": [
        "하나씩 뜯어보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLvZvMSjadl",
        "colab_type": "code",
        "outputId": "9ffd96c6-12c6-4eb3-e88f-53aa662217b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def _make_lags_for_minute(multiple, num_cycles=3):\n",
        "    # We use previous ``num_cycles`` hours to generate lags\n",
        "    return [\n",
        "        _make_lags(k * 60 // multiple, 2) for k in range(1, num_cycles + 1)\n",
        "    ]\n",
        "\n",
        "print (offset.n) # 단위: 분\n",
        "print ([(k * 60 // offset.n, 2) for k in range(1, 3 + 1)])\n",
        "print ()\n",
        "\n",
        "print (_make_lags_for_minute(offset.n)) # 한 시간 간격으로 세 시간동안 같은 분의 앞 뒤 2개씩 더 보겠다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[(12, 2), (24, 2), (36, 2)]\n",
            "\n",
            "[[10, 11, 12, 13, 14], [22, 23, 24, 25, 26], [34, 35, 36, 37, 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyDz0OTnMT0c",
        "colab_type": "code",
        "outputId": "60e39935-17f9-4257-e3d0-52a8a4a2971d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "def _make_lags_for_hour(multiple, num_cycles=7):\n",
        "    # We use previous ``num_cycles`` days to generate lags\n",
        "    return [\n",
        "        _make_lags(k * 24 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ]\n",
        "multiple = offset.n / 60.0 #(h)\n",
        "num_cycles=7\n",
        "print (multiple)\n",
        "print ([(k * 24 // multiple, 1) for k in range(1, num_cycles + 1)])\n",
        "print ([((k * 5 * 24 // multiple)/(60*24)  , 1) for k in range(1, num_cycles + 1)])\n",
        "_make_lags_for_hour(offset.n / 60.0) # 1주일 동안(1일전~7일전) 같은 시간을 중심으로 앞 뒤로 한개를 보겠다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08333333333333333\n",
            "[(288.0, 1), (576.0, 1), (864.0, 1), (1152.0, 1), (1440.0, 1), (1728.0, 1), (2016.0, 1)]\n",
            "[(1.0, 1), (2.0, 1), (3.0, 1), (4.0, 1), (5.0, 1), (6.0, 1), (7.0, 1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[287.0, 288.0, 289.0],\n",
              " [575.0, 576.0, 577.0],\n",
              " [863.0, 864.0, 865.0],\n",
              " [1151.0, 1152.0, 1153.0],\n",
              " [1439.0, 1440.0, 1441.0],\n",
              " [1727.0, 1728.0, 1729.0],\n",
              " [2015.0, 2016.0, 2017.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqfIGqPtMXgr",
        "colab_type": "code",
        "outputId": "5da00f55-88c4-44d7-f8a4-61b9650a1e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "def _make_lags_for_day(multiple, num_cycles=4):\n",
        "    # We use previous ``num_cycles`` weeks to generate lags\n",
        "    # We use the last month (in addition to 4 weeks) to generate lag.\n",
        "    return [\n",
        "        _make_lags(k * 7 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ] + [_make_lags(30 // multiple, 1)]\n",
        "\n",
        "multiple = offset.n / (60.0 * 24)\n",
        "num_cycles=4\n",
        "print (multiple)\n",
        "print ([(k * 7 // multiple, 1) for k in range(1, num_cycles + 1)])   \n",
        "\n",
        "_make_lags_for_day(offset.n / (60.0 * 24)) # 1주일 전 ~ 4주일 전, 30일 전 총 5개에 대해 같은 시간대 앞뒤로 하나씩 살펴 보겠다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003472222222222222\n",
            "[(2016.0, 1), (4032.0, 1), (6048.0, 1), (8064.0, 1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2015.0, 2016.0, 2017.0],\n",
              " [4031.0, 4032.0, 4033.0],\n",
              " [6047.0, 6048.0, 6049.0],\n",
              " [8063.0, 8064.0, 8065.0],\n",
              " [8639.0, 8640.0, 8641.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNUYpTnAMazx",
        "colab_type": "code",
        "outputId": "98a0ff23-2f4d-47bd-af7b-06051dd9ba81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "def _make_lags_for_week(multiple, num_cycles=3):\n",
        "    # We use previous ``num_cycles`` years to generate lags\n",
        "    # Additionally, we use previous 4, 8, 12 weeks\n",
        "    return [\n",
        "        _make_lags(k * 52 // multiple, 1) for k in range(1, num_cycles + 1)\n",
        "    ] + [[4 // multiple, 8 // multiple, 12 // multiple]]\n",
        "\n",
        "multiple = offset.n / (60.0 * 24 * 7)\n",
        "num_cycles=3\n",
        "print (multiple)\n",
        "print ([(k * 52 // multiple, 1) for k in range(1, num_cycles + 1)])  \n",
        "\n",
        "_make_lags_for_week(offset.n / (60.0 * 24 * 7)) # 약 1년전(52주전(364일전)), 약 2년전, 약 3년전 동일 시간 대와 앞 뒤하나씩 더 보고, 4주전, 8주전, 12주전 동일시간대도 본다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000496031746031746\n",
            "[(104832.0, 1), (209664.0, 1), (314496.0, 1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[104831.0, 104832.0, 104833.0],\n",
              " [209663.0, 209664.0, 209665.0],\n",
              " [314495.0, 314496.0, 314497.0],\n",
              " [8064.0, 16128.0, 24192.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx7ZxTKYRnFU",
        "colab_type": "code",
        "outputId": "e4a753e6-e946-449d-d57f-a624f60623e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "lags = (\n",
        "            _make_lags_for_minute(offset.n) # 전시간부터 3시간 전까지 3개\n",
        "            + _make_lags_for_hour(offset.n / 60.0) # 전날부터 7일전까지 7개\n",
        "            + _make_lags_for_day(offset.n / (60.0 * 24)) # 전주부터 4주전까지 4개 + 30일 전 1개 총 5개\n",
        "            + _make_lags_for_week(offset.n / (60.0 * 24 * 7)) # 얼추 전년부터 얼추 3년전까지 3개 + (4주,8주,12주전) 1개 총 4개\n",
        "        )\n",
        "print (len(lags))\n",
        "lags"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 11, 12, 13, 14],\n",
              " [22, 23, 24, 25, 26],\n",
              " [34, 35, 36, 37, 38],\n",
              " [287.0, 288.0, 289.0],\n",
              " [575.0, 576.0, 577.0],\n",
              " [863.0, 864.0, 865.0],\n",
              " [1151.0, 1152.0, 1153.0],\n",
              " [1439.0, 1440.0, 1441.0],\n",
              " [1727.0, 1728.0, 1729.0],\n",
              " [2015.0, 2016.0, 2017.0],\n",
              " [2015.0, 2016.0, 2017.0],\n",
              " [4031.0, 4032.0, 4033.0],\n",
              " [6047.0, 6048.0, 6049.0],\n",
              " [8063.0, 8064.0, 8065.0],\n",
              " [8639.0, 8640.0, 8641.0],\n",
              " [104831.0, 104832.0, 104833.0],\n",
              " [209663.0, 209664.0, 209665.0],\n",
              " [314495.0, 314496.0, 314497.0],\n",
              " [8064.0, 16128.0, 24192.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIfqT0zTZOU",
        "colab_type": "code",
        "outputId": "6a9acfd4-c916-4089-8794-78d5e1924b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "lag_ub = 1200\n",
        "# 7보다 크고(뒤에 다 때려 넣을 거라), lag_ub보다 작거나 같은 값만 쓰겠다.\n",
        "lags = [\n",
        "        int(lag) for sub_list in lags for lag in sub_list if 7 < lag <= lag_ub\n",
        "    ]\n",
        "print (lags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 11, 12, 13, 14, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 287, 288, 289, 575, 576, 577, 863, 864, 865, 1151, 1152, 1153]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh1dUa4yTZK3",
        "colab_type": "code",
        "outputId": "4a3e6b6b-6225-4b55-f4b0-634f6f1a6c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "lags = [1, 2, 3, 4, 5, 6, 7] + sorted(list(set(lags)))\n",
        "print (lags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 287, 288, 289, 575, 576, 577, 863, 864, 865, 1151, 1152, 1153]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FdNMuWpUWdO",
        "colab_type": "code",
        "outputId": "2f5a962c-f6cb-47d3-c4ed-00b3575fdbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "num_lags= None\n",
        "lags[:num_lags]\n",
        "print (lags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 287, 288, 289, 575, 576, 577, 863, 864, 865, 1151, 1152, 1153]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zwIkwolBLhr",
        "colab_type": "text"
      },
      "source": [
        "### get_lagged_subseuences "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymBBfJafm4hz",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/awslabs/gluon-ts/blob/d5a52c76800cf85283d488047fbe096866475064/src/gluonts/model/deepar/_network.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-vdi9fHBK6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard library imports\n",
        "import numpy as np\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "# Third-party imports\n",
        "import mxnet as mx\n",
        "from gluonts.model.common import Tensor\n",
        "def get_lagged_subsequences(\n",
        "    F,\n",
        "    sequence: Tensor,\n",
        "    sequence_length: int,\n",
        "    indices: List[int],\n",
        "    subsequences_length: int = 1,\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "    Returns lagged subsequences of a given sequence.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence : Tensor\n",
        "        the sequence from which lagged subsequences should be extracted.\n",
        "        Shape: (N, T, C).\n",
        "    sequence_length : int\n",
        "        length of sequence in the T (time) dimension (axis = 1).\n",
        "    indices : List[int]\n",
        "        list of lag indices to be used.\n",
        "    subsequences_length : int\n",
        "        length of the subsequences to be extracted.\n",
        "    Returns\n",
        "    --------\n",
        "    lagged : Tensor\n",
        "        a tensor of shape (N, S, C, I), where S = subsequences_length and\n",
        "        I = len(indices), containing lagged subsequences. Specifically,\n",
        "        lagged[i, j, :, k] = sequence[i, -indices[k]-S+j, :].\n",
        "    \"\"\"\n",
        "    # we must have: sequence_length - lag_index - subsequences_length >= 0\n",
        "    # for all lag_index, hence the following assert\n",
        "    assert max(indices) + subsequences_length <= sequence_length, (\n",
        "        f\"lags cannot go further than history length, \"\n",
        "        f\"found lag {max(indices)} while history length is only \"\n",
        "        f\"{sequence_length}\"\n",
        "    )\n",
        "    assert all(lag_index >= 0 for lag_index in indices)\n",
        "\n",
        "    lagged_values = []\n",
        "    for lag_index in indices:\n",
        "        begin_index = -lag_index - subsequences_length\n",
        "        end_index = -lag_index if lag_index > 0 else None\n",
        "        lagged_values.append(\n",
        "            F.slice_axis(\n",
        "                sequence, axis=1, begin=begin_index, end=end_index\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return F.stack(*lagged_values, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38TbW3R3BvKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = mx.nd.array([[0,1,2,3,4,5,6,7,8,9]]) # history_length로 다 땡겨 온 target value\n",
        "sequence_length = 10\n",
        "lags_seq=[3, 5] # 3개전, 5개전 값을 covariates로 쓰겠다.\n",
        "subsequences_length = 5 # 모델 학습에 필요한 데이터 집합의 수 (context_length or context_length+predcition_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug1jXOAQC7EU",
        "colab_type": "code",
        "outputId": "04c77a89-7281-40e9-81b6-f02aff693d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "feat_static_cat = mx.nd.zeros((1,10)) # 다음 셀에서 F 선언하려고 일단 만듦\n",
        "print (feat_static_cat.shape)\n",
        "feat_static_cat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
              "<NDArray 1x10 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7m40SZCPVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonts.distribution.distribution import getF\n",
        "F = getF(feat_static_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVHCy7G7BK4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lags = get_lagged_subsequences(\n",
        "            F=F,\n",
        "            sequence=sequence,\n",
        "            sequence_length=sequence_length,\n",
        "            indices=lags_seq,\n",
        "            subsequences_length=subsequences_length,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzV--qdYBK15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lagged_values = []\n",
        "indices = lags_seq\n",
        "for lag_index in indices:\n",
        "    begin_index = -lag_index - subsequences_length\n",
        "    end_index = -lag_index if lag_index > 0 else None\n",
        "    lagged_values.append(\n",
        "        F.slice_axis(\n",
        "            sequence, axis=1, begin=begin_index, end=end_index\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi4jsNFoElGL",
        "colab_type": "code",
        "outputId": "ed1c4531-95d9-47bc-e462-680f91e0ea66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "lagged_values\n",
        "# 제일 뒤 쪽 subsequeces_length에 해당하믄 [5,6,7,8,9]가 target value z 가 되고\n",
        "####### lag_index로 넘겨받은 3번째 전 값들 [2,3,4,5,6]이 첫번째 covariate x1\n",
        "####### lag_index로 넘겨받은 5번째 전 값들 [0,1,2,3,4]가 두번째 covariate x2가 되는 것 같음"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\n",
              " [[2. 3. 4. 5. 6.]]\n",
              " <NDArray 1x5 @cpu(0)>, \n",
              " [[0. 1. 2. 3. 4.]]\n",
              " <NDArray 1x5 @cpu(0)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObBWFryaGXS1",
        "colab_type": "code",
        "outputId": "07441580-3dba-44a7-c21d-2fea84e44b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "print (sequence)\n",
        "print (begin_index)\n",
        "print (end_index)\n",
        "print (lagged_values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]]\n",
            "<NDArray 1x10 @cpu(0)>\n",
            "-8\n",
            "-3\n",
            "[\n",
            "[[2. 3. 4. 5. 6.]]\n",
            "<NDArray 1x5 @cpu(0)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlBv4BnVG5Zx",
        "colab_type": "code",
        "outputId": "c84db4c7-0144-47ef-f8fb-aac5f4d62223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "F.stack(*lagged_values, axis=-1)\n",
        "# 마지막 반환이 rnn 구조에서 순차적으로 입력되기 위해 shape이 바뀌게 됨"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[2. 0.]\n",
              "  [3. 1.]\n",
              "  [4. 2.]\n",
              "  [5. 3.]\n",
              "  [6. 4.]]]\n",
              "<NDArray 1x5x2 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6HxGOQuHtNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKniJ73DmlF2",
        "colab_type": "text"
      },
      "source": [
        "### gluonts에서 공식적으로 제공하는 lag test code\n",
        "https://github.com/awslabs/gluon-ts/blob/ed847c9895fb2a225eed0596073a98babd3f31c6/test/model/deepar/test_deepar_lags.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf11-9-GLUQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "# Third-party imports\n",
        "import mxnet as mx\n",
        "\n",
        "# First-party imports\n",
        "from gluonts.model.deepar._network import DeepARTrainingNetwork\n",
        "\n",
        "N = 8\n",
        "T = 96\n",
        "C = 2\n",
        "lags = [1, 2, 3, 24, 48]\n",
        "I = len(lags)\n",
        "sequence = mx.nd.random.normal(shape=(N, T, C))\n",
        "S = 48\n",
        "\n",
        "# (batch_size, sub_seq_len, target_dim, num_lags)\n",
        "lagged_subsequences = DeepARTrainingNetwork.get_lagged_subsequences(\n",
        "    F=mx.nd,\n",
        "    sequence=sequence,\n",
        "    sequence_length=sequence.shape[1],\n",
        "    indices=lags,\n",
        "    subsequences_length=S,\n",
        ")\n",
        "\n",
        "assert (N, S, C, I) == lagged_subsequences.shape\n",
        "\n",
        "# checks that lags value behave as described as in the get_lagged_subsequences contract\n",
        "for i, j, k in itertools.product(range(N), range(S), range(I)):\n",
        "    assert (\n",
        "        (\n",
        "            lagged_subsequences[i, j, :, k]\n",
        "            == sequence[i, -lags[k] - S + j, :]\n",
        "        )\n",
        "        .asnumpy()\n",
        "        .all()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZIenAWvLZJ9",
        "colab_type": "code",
        "outputId": "8784987a-8b1a-4f9a-ab25-79385375285b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lagged_subsequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[[-0.42457297  0.6781736   1.0406365   0.65479124  2.2122064 ]\n",
              "   [-0.65036863 -0.8431705  -0.30703458 -0.45481315  0.7740038 ]]\n",
              "\n",
              "  [[-1.4775571  -0.42457297  0.6781736   0.32510808  1.0434403 ]\n",
              "   [ 0.5587636  -0.65036863 -0.8431705  -1.3002341   1.1839255 ]]\n",
              "\n",
              "  [[-0.6481019  -1.4775571  -0.42457297  0.3679345   1.8917114 ]\n",
              "   [ 0.07313449  0.5587636  -0.65036863  1.4534262  -1.2347414 ]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[ 0.8258905  -2.0099306  -0.11363573  1.9676613   1.0406365 ]\n",
              "   [ 1.0249989   1.2595973  -0.61025107 -0.00440959 -0.30703458]]\n",
              "\n",
              "  [[ 0.5808451   0.8258905  -2.0099306   2.6056926   0.6781736 ]\n",
              "   [ 0.486164    1.0249989   1.2595973   0.58565795 -0.8431705 ]]\n",
              "\n",
              "  [[-1.4802811   0.5808451   0.8258905  -0.6968178  -0.42457297]\n",
              "   [ 1.4363087   0.486164    1.0249989   0.15026927 -0.65036863]]]\n",
              "\n",
              "\n",
              " [[[-0.52480155  1.6491317  -1.436299   -0.28338912 -0.75775224]\n",
              "   [ 0.3005414  -1.2902275  -1.2416507   0.9629334   0.81197935]]\n",
              "\n",
              "  [[-1.4925312  -0.52480155  1.6491317  -1.1144744  -0.66640246]\n",
              "   [-3.2992342   0.3005414  -1.2902275   1.047153    2.7692301 ]]\n",
              "\n",
              "  [[-1.0512875  -1.4925312  -0.52480155 -0.13258979 -0.15112336]\n",
              "   [-0.30882603 -3.2992342   0.3005414   0.5115878  -0.662727  ]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[ 0.417716   -0.5388355   1.4096868   0.46784538 -1.436299  ]\n",
              "   [-1.5530336  -1.3504591  -0.55260897 -0.8634535  -1.2416507 ]]\n",
              "\n",
              "  [[ 0.926422    0.417716   -0.5388355  -0.97035617  1.6491317 ]\n",
              "   [ 0.08425415 -1.5530336  -1.3504591   0.6866476  -1.2902275 ]]\n",
              "\n",
              "  [[-1.2767951   0.926422    0.417716    0.4185587  -0.52480155]\n",
              "   [-0.03780347  0.08425415 -1.5530336  -0.26519665  0.3005414 ]]]\n",
              "\n",
              "\n",
              " [[[-0.94700885 -1.3841926   0.48732397 -0.41308445 -1.0929538 ]\n",
              "   [-1.1014541  -0.19262609 -2.152955    0.6788356  -0.1200345 ]]\n",
              "\n",
              "  [[-0.41594216 -0.94700885 -1.3841926   0.19221152 -0.8580494 ]\n",
              "   [ 2.0085082  -1.1014541  -0.19262609  0.9686524   2.3553243 ]]\n",
              "\n",
              "  [[-1.3542701  -0.41594216 -0.94700885 -0.09838036  0.92821044]\n",
              "   [-1.2779027   2.0085082  -1.1014541  -0.08484158 -0.21817116]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[-1.0249715  -1.6575857   2.0979002   0.8605494   0.48732397]\n",
              "   [ 1.47838     1.4283854  -2.5541635  -0.22276537 -2.152955  ]]\n",
              "\n",
              "  [[ 1.0745716  -1.0249715  -1.6575857  -1.8834633  -1.3841926 ]\n",
              "   [-0.11895143  1.47838     1.4283854  -0.15658343 -0.19262609]]\n",
              "\n",
              "  [[ 1.3848708   1.0745716  -1.0249715  -0.41436312 -0.94700885]\n",
              "   [-0.97938746 -0.11895143  1.47838    -0.71531004 -1.1014541 ]]]\n",
              "\n",
              "\n",
              " ...\n",
              "\n",
              "\n",
              " [[[ 2.310595    1.1208912  -0.08512726  0.79578614  0.33800116]\n",
              "   [ 1.1056191   1.2570045  -0.90995044 -1.46124     0.34782964]]\n",
              "\n",
              "  [[-0.5541078   2.310595    1.1208912   0.24290131  1.106874  ]\n",
              "   [-0.02885367  1.1056191   1.2570045   0.2963081   0.33742583]]\n",
              "\n",
              "  [[-0.7437719  -0.5541078   2.310595    0.8711869  -0.44275877]\n",
              "   [ 0.56905705 -0.02885367  1.1056191  -1.8043553   0.91375124]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[-0.19236775  0.5622029   0.8636369  -0.01816701 -0.08512726]\n",
              "   [ 1.1829971  -0.9910388   0.7860209  -1.2895633  -0.90995044]]\n",
              "\n",
              "  [[-0.03632846 -0.19236775  0.5622029  -1.0160087   1.1208912 ]\n",
              "   [ 0.24389063  1.1829971  -0.9910388  -1.6166807   1.2570045 ]]\n",
              "\n",
              "  [[-0.65354335 -0.03632846 -0.19236775 -2.3455238   2.310595  ]\n",
              "   [ 0.3661118   0.24389063  1.1829971  -0.20841935  1.1056191 ]]]\n",
              "\n",
              "\n",
              " [[[-0.5134857   0.9507462   1.1124251  -0.3774956  -0.61270916]\n",
              "   [-2.0474763  -1.2064103  -0.8271374  -1.6566036  -2.8199658 ]]\n",
              "\n",
              "  [[-0.14752641 -0.5134857   0.9507462   1.6114203  -0.3365844 ]\n",
              "   [-0.4814555  -2.0474763  -1.2064103   0.59097415 -0.3710372 ]]\n",
              "\n",
              "  [[-0.91107726 -0.14752641 -0.5134857  -1.3388257  -0.81110424]\n",
              "   [-0.1736352  -0.4814555  -2.0474763   0.87608916  0.03386728]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[-0.8474277   1.8510491   0.78226787 -0.11983846  1.1124251 ]\n",
              "   [ 0.91881126  1.5047357  -0.6742348  -0.7142324  -0.8271374 ]]\n",
              "\n",
              "  [[-0.18462065 -0.8474277   1.8510491   0.46208316  0.9507462 ]\n",
              "   [-1.4264767   0.91881126  1.5047357  -0.15631126 -1.2064103 ]]\n",
              "\n",
              "  [[ 0.36715728 -0.18462065 -0.8474277  -0.8624608  -0.5134857 ]\n",
              "   [-0.7350839  -1.4264767   0.91881126 -0.4348689  -2.0474763 ]]]\n",
              "\n",
              "\n",
              " [[[ 0.44809967 -1.38561    -2.060632    0.07947154  0.9968283 ]\n",
              "   [ 0.00624379  1.8960966   0.3866247   1.125432    0.6547287 ]]\n",
              "\n",
              "  [[ 1.4309155   0.44809967 -1.38561    -0.3418468   0.82645124]\n",
              "   [-0.01514311  0.00624379  1.8960966  -0.6434393  -1.2338163 ]]\n",
              "\n",
              "  [[ 0.00389364  1.4309155   0.44809967  0.39862037  0.9152749 ]\n",
              "   [ 1.1413413  -0.01514311  0.00624379  0.796254   -1.2217913 ]]\n",
              "\n",
              "  ...\n",
              "\n",
              "  [[-1.1554946   0.16578287  0.17241147  0.12527315 -2.060632  ]\n",
              "   [-0.02477526 -0.10867531 -0.05804389 -0.8017047   0.3866247 ]]\n",
              "\n",
              "  [[-0.3930928  -1.1554946   0.16578287 -0.17710795 -1.38561   ]\n",
              "   [-1.5056137  -0.02477526 -0.10867531 -0.3972993   1.8960966 ]]\n",
              "\n",
              "  [[ 0.25672248 -0.3930928  -1.1554946   1.4890484   0.44809967]\n",
              "   [ 0.7282488  -1.5056137  -0.02477526  0.2907722   0.00624379]]]]\n",
              "<NDArray 8x48x2x5 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "733I1yVGLeng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}