{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Electricity_DeepAR_DeepFactor",
      "provenance": [],
      "collapsed_sections": [
        "S2jXmEKk5Rm5"
      ],
      "authorship_tag": "ABX9TyN5FalrLKbc+hHd1uoqsSa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/GluonTS/blob/master/Electricity_DeepAR_DeepFactor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtkVPqoH9Rfy",
        "colab_type": "text"
      },
      "source": [
        "## 환경 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CSLjjP49WWM",
        "colab_type": "text"
      },
      "source": [
        "Colab에서 어떤 GPU가 할당되었는 지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ0D8LcKy2vu",
        "colab_type": "code",
        "outputId": "554727b0-bfbc-4e0c-f97d-18ceff85ff4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 22 01:10:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfXmDXu9b8y",
        "colab_type": "text"
      },
      "source": [
        "MXNET 설치 \n",
        "- GluonTS는 Amazon이 2019년 공개한 Tool로서 MXNET을 backbone으로 사용\n",
        "  - https://aws.amazon.com/blogs/machine-learning/creating-neural-time-series-models-with-gluon-time-series/\n",
        "\n",
        "- 어떤 버전의 MXNET을 설치해야 하는 지는 아래 링크 참고\n",
        "  - https://mxnet.apache.org/get_started/?platform=linux&language=python&processor=gpu&environ=pip&"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpYiCxWFwrdF",
        "colab_type": "code",
        "outputId": "c27cfffd-f125-4c5b-c5dc-17ea6d9ecbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# nvidia-smi로 CUDA Version 확인하고 해당되는 MXNET 설치\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b1/7d01abca10eef104296d2b3f0c59a7dda7573126d079c9e2609e6c17993b/mxnet_cu101-1.6.0-py2.py3-none-manylinux1_x86_64.whl (710.5MB)\n",
            "\u001b[K     |████████████████████████████████| 710.5MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrgwGyjH-_1K",
        "colab_type": "text"
      },
      "source": [
        "GluonTS를 설치함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O45K03dixX4N",
        "colab_type": "code",
        "outputId": "b453d2e8-3b84-4442-9a16-845d7859d6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "!pip install gluonts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/07/5a63f7d645761982743d375fc816120b680e0de13ac139829e509b3206fc/gluonts-0.5.0-py3-none-any.whl (419kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 8.5MB/s \n",
            "\u001b[?25hCollecting ujson~=1.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (3.2.1)\n",
            "Requirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (1.0.3)\n",
            "Collecting pydantic~=1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/c9/7d664fbe54863b92cea790c7305915888c2f13a68a754893d8291bab0d0d/pydantic-1.5.1-cp36-cp36m-manylinux2014_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.6/dist-packages (from gluonts) (1.18.4)\n",
            "Requirement already satisfied: holidays<0.10,>=0.9 in /usr/local/lib/python3.6/dist-packages (from gluonts) (0.9.12)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.6/dist-packages (from gluonts) (4.41.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0->gluonts) (2018.9)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic~=1.1->gluonts) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays<0.10,>=0.9->gluonts) (1.12.0)\n",
            "Building wheels for collected packages: ujson\n",
            "  Building wheel for ujson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ujson: filename=ujson-1.35-cp36-cp36m-linux_x86_64.whl size=68028 sha256=4f42bcb003f3282444347fad1bd2e13038c45df5caf9905c1e7ec48ed7c9bf5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "Successfully built ujson\n",
            "Installing collected packages: ujson, pydantic, gluonts\n",
            "Successfully installed gluonts-0.5.0 pydantic-1.5.1 ujson-1.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmbEt0H9GYBt",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS73SazB-iAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Third-party imports\n",
        "%matplotlib inline\n",
        "import mxnet as mx\n",
        "from mxnet import gluon\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from itertools import islice\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUyHYjzGRi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mx.random.seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyFHxQYCGWpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
        "from gluonts.dataset.util import to_pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brbJTfB7GhNs",
        "colab_type": "code",
        "outputId": "28ca7db8-968a-40bb-bd2b-ad69cc57b951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(f\"Available datasets: {list(dataset_recipes.keys())}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available datasets: ['constant', 'exchange_rate', 'solar-energy', 'electricity', 'traffic', 'exchange_rate_nips', 'electricity_nips', 'traffic_nips', 'solar_nips', 'wiki-rolling_nips', 'taxi_30min', 'm4_hourly', 'm4_daily', 'm4_weekly', 'm4_monthly', 'm4_quarterly', 'm4_yearly', 'm5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLZkazZs5K0n",
        "colab_type": "text"
      },
      "source": [
        "### Electricity 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUlhWYZLGqAa",
        "colab_type": "code",
        "outputId": "874841b9-704e-42cc-b558-1db5f23b4886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dataset = get_dataset(\"electricity\", regenerate=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving time-series into /root/.mxnet/gluon-ts/datasets/electricity/train/data.json\n",
            "saving time-series into /root/.mxnet/gluon-ts/datasets/electricity/test/data.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSE3rXs2HA4L",
        "colab_type": "text"
      },
      "source": [
        "train data entry의 각 Field 확인 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWY1DJ_oGs9v",
        "colab_type": "code",
        "outputId": "6e3eec10-8dbf-401d-f3f6-6f7064d1dc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# get the first time series in the training set\n",
        "# training dataset의 첫번째 entry를 보겠음\n",
        "### entry에는 start field, target field, feat_statc_cat filed, source filed가 있음\n",
        "train_entry = next(iter(dataset.train))\n",
        "train_entry.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['start', 'target', 'feat_static_cat', 'item_id', 'source'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwuqyvY8sOmI",
        "colab_type": "code",
        "outputId": "b3281a75-b8ba-4da9-9a0e-e555bb189be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## train entry 개수(데이터 개수) 확인\n",
        "i = 0\n",
        "for _ in iter(dataset.train):\n",
        "  i+=1\n",
        "print (i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlgkAAk46_wX",
        "colab_type": "code",
        "outputId": "15e4ca51-5a93-4cc1-dbf9-13bdd8c5cce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# YJ\n",
        "## train entry 개수(데이터 개수) 확인\n",
        "for train_entry in iter(dataset.train):\n",
        "  print (train_entry['feat_static_cat'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[1]\n",
            "[2]\n",
            "[3]\n",
            "[4]\n",
            "[5]\n",
            "[6]\n",
            "[7]\n",
            "[8]\n",
            "[9]\n",
            "[10]\n",
            "[11]\n",
            "[12]\n",
            "[13]\n",
            "[14]\n",
            "[15]\n",
            "[16]\n",
            "[17]\n",
            "[18]\n",
            "[19]\n",
            "[20]\n",
            "[21]\n",
            "[22]\n",
            "[23]\n",
            "[24]\n",
            "[25]\n",
            "[26]\n",
            "[27]\n",
            "[28]\n",
            "[29]\n",
            "[30]\n",
            "[31]\n",
            "[32]\n",
            "[33]\n",
            "[34]\n",
            "[35]\n",
            "[36]\n",
            "[37]\n",
            "[38]\n",
            "[39]\n",
            "[40]\n",
            "[41]\n",
            "[42]\n",
            "[43]\n",
            "[44]\n",
            "[45]\n",
            "[46]\n",
            "[47]\n",
            "[48]\n",
            "[49]\n",
            "[50]\n",
            "[51]\n",
            "[52]\n",
            "[53]\n",
            "[54]\n",
            "[55]\n",
            "[56]\n",
            "[57]\n",
            "[58]\n",
            "[59]\n",
            "[60]\n",
            "[61]\n",
            "[62]\n",
            "[63]\n",
            "[64]\n",
            "[65]\n",
            "[66]\n",
            "[67]\n",
            "[68]\n",
            "[69]\n",
            "[70]\n",
            "[71]\n",
            "[72]\n",
            "[73]\n",
            "[74]\n",
            "[75]\n",
            "[76]\n",
            "[77]\n",
            "[78]\n",
            "[79]\n",
            "[80]\n",
            "[81]\n",
            "[82]\n",
            "[83]\n",
            "[84]\n",
            "[85]\n",
            "[86]\n",
            "[87]\n",
            "[88]\n",
            "[89]\n",
            "[90]\n",
            "[91]\n",
            "[92]\n",
            "[93]\n",
            "[94]\n",
            "[95]\n",
            "[96]\n",
            "[97]\n",
            "[98]\n",
            "[99]\n",
            "[100]\n",
            "[101]\n",
            "[102]\n",
            "[103]\n",
            "[104]\n",
            "[105]\n",
            "[106]\n",
            "[107]\n",
            "[108]\n",
            "[109]\n",
            "[110]\n",
            "[111]\n",
            "[112]\n",
            "[113]\n",
            "[114]\n",
            "[115]\n",
            "[116]\n",
            "[117]\n",
            "[118]\n",
            "[119]\n",
            "[120]\n",
            "[121]\n",
            "[122]\n",
            "[123]\n",
            "[124]\n",
            "[125]\n",
            "[126]\n",
            "[127]\n",
            "[128]\n",
            "[129]\n",
            "[130]\n",
            "[131]\n",
            "[132]\n",
            "[133]\n",
            "[134]\n",
            "[135]\n",
            "[136]\n",
            "[137]\n",
            "[138]\n",
            "[139]\n",
            "[140]\n",
            "[141]\n",
            "[142]\n",
            "[143]\n",
            "[144]\n",
            "[145]\n",
            "[146]\n",
            "[147]\n",
            "[148]\n",
            "[149]\n",
            "[150]\n",
            "[151]\n",
            "[152]\n",
            "[153]\n",
            "[154]\n",
            "[155]\n",
            "[156]\n",
            "[157]\n",
            "[158]\n",
            "[159]\n",
            "[160]\n",
            "[161]\n",
            "[162]\n",
            "[163]\n",
            "[164]\n",
            "[165]\n",
            "[166]\n",
            "[167]\n",
            "[168]\n",
            "[169]\n",
            "[170]\n",
            "[171]\n",
            "[172]\n",
            "[173]\n",
            "[174]\n",
            "[175]\n",
            "[176]\n",
            "[177]\n",
            "[178]\n",
            "[179]\n",
            "[180]\n",
            "[181]\n",
            "[182]\n",
            "[183]\n",
            "[184]\n",
            "[185]\n",
            "[186]\n",
            "[187]\n",
            "[188]\n",
            "[189]\n",
            "[190]\n",
            "[191]\n",
            "[192]\n",
            "[193]\n",
            "[194]\n",
            "[195]\n",
            "[196]\n",
            "[197]\n",
            "[198]\n",
            "[199]\n",
            "[200]\n",
            "[201]\n",
            "[202]\n",
            "[203]\n",
            "[204]\n",
            "[205]\n",
            "[206]\n",
            "[207]\n",
            "[208]\n",
            "[209]\n",
            "[210]\n",
            "[211]\n",
            "[212]\n",
            "[213]\n",
            "[214]\n",
            "[215]\n",
            "[216]\n",
            "[217]\n",
            "[218]\n",
            "[219]\n",
            "[220]\n",
            "[221]\n",
            "[222]\n",
            "[223]\n",
            "[224]\n",
            "[225]\n",
            "[226]\n",
            "[227]\n",
            "[228]\n",
            "[229]\n",
            "[230]\n",
            "[231]\n",
            "[232]\n",
            "[233]\n",
            "[234]\n",
            "[235]\n",
            "[236]\n",
            "[237]\n",
            "[238]\n",
            "[239]\n",
            "[240]\n",
            "[241]\n",
            "[242]\n",
            "[243]\n",
            "[244]\n",
            "[245]\n",
            "[246]\n",
            "[247]\n",
            "[248]\n",
            "[249]\n",
            "[250]\n",
            "[251]\n",
            "[252]\n",
            "[253]\n",
            "[254]\n",
            "[255]\n",
            "[256]\n",
            "[257]\n",
            "[258]\n",
            "[259]\n",
            "[260]\n",
            "[261]\n",
            "[262]\n",
            "[263]\n",
            "[264]\n",
            "[265]\n",
            "[266]\n",
            "[267]\n",
            "[268]\n",
            "[269]\n",
            "[270]\n",
            "[271]\n",
            "[272]\n",
            "[273]\n",
            "[274]\n",
            "[275]\n",
            "[276]\n",
            "[277]\n",
            "[278]\n",
            "[279]\n",
            "[280]\n",
            "[281]\n",
            "[282]\n",
            "[283]\n",
            "[284]\n",
            "[285]\n",
            "[286]\n",
            "[287]\n",
            "[288]\n",
            "[289]\n",
            "[290]\n",
            "[291]\n",
            "[292]\n",
            "[293]\n",
            "[294]\n",
            "[295]\n",
            "[296]\n",
            "[297]\n",
            "[298]\n",
            "[299]\n",
            "[300]\n",
            "[301]\n",
            "[302]\n",
            "[303]\n",
            "[304]\n",
            "[305]\n",
            "[306]\n",
            "[307]\n",
            "[308]\n",
            "[309]\n",
            "[310]\n",
            "[311]\n",
            "[312]\n",
            "[313]\n",
            "[314]\n",
            "[315]\n",
            "[316]\n",
            "[317]\n",
            "[318]\n",
            "[319]\n",
            "[320]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwTsXCJj9Vo",
        "colab_type": "code",
        "outputId": "882ac67b-ffa5-4b00-daa0-28f98ff16655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## Start filed 확인\n",
        "print (train_entry['start'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2012-01-01 00:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_99D2czDkJSA",
        "colab_type": "code",
        "outputId": "cc23add4-c2aa-4333-e800-6d926b059488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## target filed 길이 확인(time serise 길이)\n",
        "print (train_entry['target'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21044,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTeB-4dykI_V",
        "colab_type": "code",
        "outputId": "d60160d8-abdb-4afc-e66a-d6d09dcf11f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# YJ\n",
        "## target field target value 앞뒤로 10개씩 확인\n",
        "print (train_entry['target'][:10])\n",
        "print (train_entry['target'][-10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14. 18. 21. 20. 22. 20. 20. 20. 13. 11.]\n",
            "[6. 4. 4. 2. 2. 4. 8. 6. 9. 7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYNEvJ_8kI62",
        "colab_type": "code",
        "outputId": "8d6a9a14-c7f2-4b31-c4d1-990c0476f272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## 'feat_static_cat' field 확인\n",
        "## 'feat_static_cat' field는 일단 여기서 무시하고 넘어가고 나중에 다루겠다 함\n",
        "print (train_entry['feat_static_cat'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMDeiH48kjvr",
        "colab_type": "code",
        "outputId": "5c39af6b-a386-4e7d-9c1c-50810e7e64b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## source field 확인\n",
        "## source는 데이터가 저장되어 있는 경로에 대한 정보를 담고 있는 것 같음\n",
        "print (train_entry['source'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SourceContext(source=PosixPath('/root/.mxnet/gluon-ts/datasets/electricity/train/data.json'), row=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEP_Xdl6QokT",
        "colab_type": "text"
      },
      "source": [
        "We can similarly examine the first entry of the test dataset. We should expect exactly the same fields as in the train dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Fq3aT5qlOLc"
      },
      "source": [
        "##### test data entry의 각 Field 확인 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZvchhPDIBas",
        "colab_type": "code",
        "outputId": "02d00d46-e141-4377-adbe-f38a86206fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# get the first time series in the test set\n",
        "test_entry = next(iter(dataset.test))\n",
        "test_entry.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['start', 'target', 'feat_static_cat', 'item_id', 'source'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cokISsuschG",
        "colab_type": "code",
        "outputId": "cf80c641-c7af-4410-9f0a-afb0f7a7e1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "## test entry 개수(데이터 개수) 확인\n",
        "### train entry 개수(414)와 같음\n",
        "i = 0\n",
        "for _ in iter(dataset.test):\n",
        "  i+=1\n",
        "print (i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A_vdpwg6lOLe",
        "outputId": "b33fc844-ab17-430e-dead-b9bae2bfa870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# YJ\n",
        "## 'start' field 확인\n",
        "### train data, test data 동일\n",
        "print (train_entry['start'])\n",
        "print (test_entry['start'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2012-01-01 00:00:00\n",
            "2012-01-01 00:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ntsYDfeulOLi",
        "outputId": "31fb41ca-1e70-40d9-fca1-f22f7a63f3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# YJ\n",
        "## target 길이 비교\n",
        "## test data가 prediction_length만큼 더 김\n",
        "print (train_entry['target'].shape)\n",
        "print (test_entry['target'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21044,)\n",
            "(21068,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t26XL_DilOLl",
        "outputId": "d4bbfa85-5ffb-4979-c4cc-675d037602ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "# YJ\n",
        "## target value 비교\n",
        "print (train_entry['target'][:10])\n",
        "print (test_entry['target'][:10])\n",
        "print ()\n",
        "print (train_entry['target'][-10:])\n",
        "print (test_entry['target'][-58:-48])\n",
        "print (test_entry['target'][-10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14. 18. 21. 20. 22. 20. 20. 20. 13. 11.]\n",
            "[14. 18. 21. 20. 22. 20. 20. 20. 13. 11.]\n",
            "\n",
            "[6. 4. 4. 2. 2. 4. 8. 6. 9. 7.]\n",
            "[4. 2. 2. 2. 4. 6. 6. 7. 4. 8.]\n",
            "[6. 2. 2. 2. 4. 2. 6. 8. 8. 6.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exN-coJnlOLp",
        "outputId": "f0f1393d-4929-40b4-e2ab-708ffe95a129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# YJ\n",
        "## 'feat_Static_cat' 비교\n",
        "## 'feat_static_cat' filed는 일단 여기서 무시하고 넘어가고 나중에 다루겠다 함\n",
        "print (train_entry['feat_static_cat'])\n",
        "print (test_entry['feat_static_cat'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pGMoDw40lOLs",
        "outputId": "73696cf9-1e7a-4b54-e3ba-3c1c91f9aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# YJ\n",
        "## 'source' filed 비교\n",
        "## source는 데이터가 저장되어 있는 경로에 대한 정보를 담고 있는 것 같음\n",
        "print (train_entry['source'])\n",
        "print (test_entry['source'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SourceContext(source=PosixPath('/root/.mxnet/gluon-ts/datasets/electricity/train/data.json'), row=0)\n",
            "SourceContext(source=PosixPath('/root/.mxnet/gluon-ts/datasets/electricity/test/data.json'), row=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0qsVIZO0Ox2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_it = iter(dataset.test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "02d00d46-e141-4377-adbe-f38a86206fd8",
        "id": "2Rjptryo0SSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# get the first time series in the test set\n",
        "test_entry = next(iter(dataset.test))\n",
        "test_entry.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['start', 'target', 'feat_static_cat', 'item_id', 'source'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R7hRISSO0SS5",
        "colab": {}
      },
      "source": [
        "# YJ\n",
        "## test entry 개수(데이터 개수) 확인\n",
        "### train entry 개수(414)와 같음\n",
        "target_list = []\n",
        "for test_entry in iter(dataset.test):\n",
        "  target_list.append(test_entry['target'][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMs-kVVg0gzA",
        "colab_type": "code",
        "outputId": "55280f81-2841-4ef5-a5d6-f9c2b4ea68c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print (len(target_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXfpnpMD08be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YJ\n",
        "## test entry 개수(데이터 개수) 확인\n",
        "### train entry 개수(414)와 같음\n",
        "target_list = []\n",
        "for test_entry in iter(dataset.test):\n",
        "  target = str(test_entry['target'][:10])\n",
        "  print (type(target))\n",
        "  if target not in target_list:\n",
        "    target_list.append(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRRONsfW1R7P",
        "colab_type": "code",
        "outputId": "33614eb8-8092-4d7b-c884-232c09d8cbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(target_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtp4lyzy2NI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YJ\n",
        "## test entry 개수(데이터 개수) 확인\n",
        "### train entry 개수(414)와 같음\n",
        "target_shape = []\n",
        "for test_entry in iter(dataset.test):\n",
        "  target_shape.append(test_entry['target'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtVroPz2k9_",
        "colab_type": "code",
        "outputId": "72931bf4-b73d-4cfc-e438-7ef119b3ebc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "set(target_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(21068,), (21092,), (21116,), (21140,), (21164,), (21188,), (21212,)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQlaYRTv42Gc",
        "colab_type": "text"
      },
      "source": [
        "test_data가 1일(24시간), 2일, 3일, 4일, 5일, 6일, 7일로 되어 있어서 train data 개수(321)보다 7배 더 많음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mwZ1qKD2_pt",
        "colab_type": "code",
        "outputId": "da50ab1f-2a7f-4f6d-fe1f-048fc5c72a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print (dataset.metadata)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "freq='1H' target=None feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat', cardinality='321')] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMsZNm708Z5D",
        "colab_type": "code",
        "outputId": "bfcb02cf-c972-467b-84d6-29dad1a8b87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dataset.metadata.feat_static_cat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CategoricalFeatureInfo(name='feat_static_cat', cardinality='321')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbPo1rHY7nGe",
        "colab_type": "text"
      },
      "source": [
        "## Estimator 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwbJirQ67oj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonts.model.deepar import DeepAREstimator\n",
        "from gluonts.distribution.gaussian import GaussianOutput\n",
        "from gluonts.trainer import Trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s2MJmWi-OcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.trainer.html\n",
        "deepar_trainer=Trainer(\n",
        "    ctx = 'gpu',\n",
        "    epochs=100, # Number of epochs that the network will train (default: 100).\n",
        "    batch_size=64,# Number of examples in each batch (default: 32).\n",
        "    num_batches_per_epoch=78, # Number of batches at each epoch (default: 50).\n",
        "    learning_rate=1e-3, # Initial learning rate (default:  1e−3 ).\n",
        "    learning_rate_decay_factor=0.1, # Factor (between 0 and 1) by which to decrease the learning rate (default: 0.5).\n",
        "    patience = 30, # The patience to observe before reducing the learning rate, nonnegative integer (default: 10).\n",
        "    minimum_learning_rate=1e-6, #  Lower bound for the learning rate (default:  5⋅10−5 ).\n",
        "    clip_gradient = 10, # Maximum value of gradient. The gradient is clipped if it is too large (default: 10).\n",
        "    weight_decay=1e-8, # The weight decay (or L2 regularization) coefficient. Modifies objective by adding a penalty for having large weights (default  10−8 ).\n",
        "    init='xavier', # Initializer of the weights of the network (default: “xavier”).\n",
        "    hybridize=False, ## ???????\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JcLRSl6BmUc",
        "colab_type": "text"
      },
      "source": [
        "hybridize 관련해서는 이슈가 있는 듯\n",
        "- https://github.com/awslabs/gluon-ts/issues/833\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA2KTd9q-PlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.model.deepar.html\n",
        "estimator = DeepAREstimator(\n",
        "    freq=dataset.metadata.freq, # Frequency of the data to train on and predict\n",
        "    prediction_length=dataset.metadata.prediction_length, # Length of the prediction horizon\n",
        "    trainer = deepar_trainer, # Trainer object to be used (default: Trainer())\n",
        "    context_length=dataset.metadata.prediction_length, # Number of steps to unroll the RNN for before computing predictions (default: None, in which case context_length = prediction_length)\n",
        "    num_layers=3, # Number of RNN layers (default: 2)\n",
        "    num_cells=40, # Number of RNN cells for each layer (default: 40)\n",
        "    cell_type='lstm', # Type of recurrent cells to use (available: ‘lstm’ or ‘gru’; default: ‘lstm’)\n",
        "    dropout_rate=0.1, # Dropout regularization parameter (default: 0.1)\n",
        "    use_feat_dynamic_real=False, # Whether to use the feat_dynamic_real field from the data (default: False)\n",
        "    use_feat_static_cat=True, # Whether to use the feat_static_cat field from the data (default: False)\n",
        "    use_feat_static_real=False, # Whether to use the feat_static_real field from the data (default: False)\n",
        "    cardinality=[321], # Number of values of each categorical feature. This must be set if use_feat_static_cat == True (default: None)\n",
        "    embedding_dimension=[20], # Dimension of the embeddings for categorical features (default: [min(50, (cat+1)//2) for cat in cardinality])\n",
        "    distr_output = GaussianOutput(), # Distribution to use to evaluate observations and sample predictions (default: StudentTOutput())\n",
        "    scaling=True, # Whether to automatically scale the target values (default: true)\n",
        "    lags_seq=None, # Indices of the lagged target values to use as inputs of the RNN (default: None, in which case these are automatically determined based on freq)\n",
        "    time_features=None, # Time features to use as inputs of the RNN (default: None, in which case these are automatically determined based on freq)\n",
        "    num_parallel_samples=1024, # Number of evaluation samples per time series to increase parallelism during inference. This is a model optimization that does not affect the accuracy (default: 100)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0fS02K3-Rfr",
        "colab_type": "code",
        "outputId": "03d07c74-a39c-49ef-fddc-800e8f61b79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictor = estimator.train(dataset.train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=1/100, avg_epoch_loss=6.4]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=2/100, avg_epoch_loss=5.92]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=3/100, avg_epoch_loss=5.78]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=4/100, avg_epoch_loss=5.67]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=5/100, avg_epoch_loss=5.64]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=6/100, avg_epoch_loss=5.53]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=7/100, avg_epoch_loss=5.46]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=8/100, avg_epoch_loss=5.47]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=9/100, avg_epoch_loss=5.41]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=10/100, avg_epoch_loss=5.48]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=11/100, avg_epoch_loss=5.41]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=12/100, avg_epoch_loss=5.43]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=13/100, avg_epoch_loss=5.37]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=14/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=15/100, avg_epoch_loss=5.35]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=16/100, avg_epoch_loss=5.39]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=17/100, avg_epoch_loss=5.35]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=18/100, avg_epoch_loss=5.34]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=19/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=20/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=21/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=22/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=23/100, avg_epoch_loss=5.32]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=24/100, avg_epoch_loss=5.3] \n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=25/100, avg_epoch_loss=5.3] \n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=26/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=27/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=28/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=29/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=30/100, avg_epoch_loss=5.31]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=31/100, avg_epoch_loss=5.32]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=32/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 78/78 [01:11<00:00,  1.08it/s, epoch=33/100, avg_epoch_loss=5.26]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=34/100, avg_epoch_loss=5.3]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=35/100, avg_epoch_loss=5.26]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=36/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=37/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=38/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=39/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=40/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=41/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=42/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=43/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=44/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=45/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=46/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=47/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=48/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=49/100, avg_epoch_loss=5.2] \n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=50/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=51/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=52/100, avg_epoch_loss=5.34]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=53/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=54/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=55/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=56/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=57/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=58/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:11<00:00,  1.09it/s, epoch=59/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=60/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=61/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=62/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=63/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=64/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=65/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=66/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=67/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=68/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.05it/s, epoch=69/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=70/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=71/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=72/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=73/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=74/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.05it/s, epoch=75/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=76/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=77/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=78/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=79/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=80/100, avg_epoch_loss=5.14]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=81/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=82/100, avg_epoch_loss=5.12]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=83/100, avg_epoch_loss=5.18]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=84/100, avg_epoch_loss=5.15]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=85/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=86/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=87/100, avg_epoch_loss=5.13]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=88/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.05it/s, epoch=89/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.05it/s, epoch=90/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.04it/s, epoch=91/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.08it/s, epoch=92/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.07it/s, epoch=93/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=94/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=95/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 78/78 [01:14<00:00,  1.05it/s, epoch=96/100, avg_epoch_loss=5.15]\n",
            "100%|██████████| 78/78 [01:12<00:00,  1.07it/s, epoch=97/100, avg_epoch_loss=5.14]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=98/100, avg_epoch_loss=5.11]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=99/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 78/78 [01:13<00:00,  1.06it/s, epoch=100/100, avg_epoch_loss=5.15]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vs-sQ8jAo4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
        "from gluonts.evaluation import Evaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pcec0klf8PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=dataset.train,  # test dataset\n",
        "    predictor=predictor,  # predictor\n",
        "    num_samples=300,  # number of sample paths we want for evaluation\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HSMLOZRf9pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset에 있는 데이터 개수 만큼이 만들어짐\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n0wZMGyf-_b",
        "colab_type": "code",
        "outputId": "d26c1c03-17e5-40ef-e329-fea731d541a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
        "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(dataset.train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running evaluation: 100%|██████████| 321/321 [00:00<00:00, 3860.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXYXPCbRgAw6",
        "colab_type": "code",
        "outputId": "f22137d9-ed5b-4103-e91e-1ce4bae30c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "# sampling 결과다 보니, sample paths를 다시 만들 때마다 값이 조금씩 달라지기는 함\n",
        "## 어느 시점의 값을 결과로 사용해야 하는 걸까???????????\n",
        "print(json.dumps(agg_metrics, indent=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"MSE\": 447648.2037265956,\n",
            "    \"abs_error\": 1044650.9386005402,\n",
            "    \"abs_target_sum\": 16669730.0,\n",
            "    \"abs_target_mean\": 2163.7759605399806,\n",
            "    \"seasonal_error\": 189.65640599692924,\n",
            "    \"MASE\": 0.7864342682619653,\n",
            "    \"MAPE\": 0.08320297333314597,\n",
            "    \"sMAPE\": 0.11279543998530832,\n",
            "    \"OWA\": NaN,\n",
            "    \"MSIS\": 7.792327860451494,\n",
            "    \"QuantileLoss[0.1]\": 545700.8693288207,\n",
            "    \"Coverage[0.1]\": 0.03361889927310486,\n",
            "    \"QuantileLoss[0.5]\": 1044650.9407185093,\n",
            "    \"Coverage[0.5]\": 0.38356697819314667,\n",
            "    \"QuantileLoss[0.9]\": 578568.6512193321,\n",
            "    \"Coverage[0.9]\": 0.8783748701973004,\n",
            "    \"RMSE\": 669.0651715091705,\n",
            "    \"NRMSE\": 0.30921185174004895,\n",
            "    \"ND\": 0.06266753802254386,\n",
            "    \"wQuantileLoss[0.1]\": 0.03273603527644543,\n",
            "    \"wQuantileLoss[0.5]\": 0.06266753814959866,\n",
            "    \"wQuantileLoss[0.9]\": 0.03470773979058642,\n",
            "    \"mean_wQuantileLoss\": 0.04337043773887683,\n",
            "    \"MAE_Coverage\": 0.0681464174454827\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HynxncdRgCXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QS_S0KbgZZm",
        "colab_type": "text"
      },
      "source": [
        "hybridze=True인 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkAEMp85gbbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.trainer.html\n",
        "deepar_trainer2=Trainer(\n",
        "    ctx = 'gpu',\n",
        "    epochs=100, # Number of epochs that the network will train (default: 100).\n",
        "    batch_size=256,# Number of examples in each batch (default: 32).\n",
        "    num_batches_per_epoch=20, # Number of batches at each epoch (default: 50).\n",
        "    learning_rate=1e-2, # Initial learning rate (default:  1e−3 ).\n",
        "    learning_rate_decay_factor=0.5, # Factor (between 0 and 1) by which to decrease the learning rate (default: 0.5).\n",
        "    patience = 20, # The patience to observe before reducing the learning rate, nonnegative integer (default: 10).\n",
        "    minimum_learning_rate=1e-6, #  Lower bound for the learning rate (default:  5⋅10−5 ).\n",
        "    clip_gradient = 10, # Maximum value of gradient. The gradient is clipped if it is too large (default: 10).\n",
        "    weight_decay=1e-8, # The weight decay (or L2 regularization) coefficient. Modifies objective by adding a penalty for having large weights (default  10−8 ).\n",
        "    init='xavier', # Initializer of the weights of the network (default: “xavier”).\n",
        "    hybridize=False, ## ???????\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvcY0QVGgeRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.model.deepar.html\n",
        "estimator2 = DeepAREstimator(\n",
        "    freq=dataset.metadata.freq, # Frequency of the data to train on and predict\n",
        "    prediction_length=dataset.metadata.prediction_length, # Length of the prediction horizon\n",
        "    trainer = deepar_trainer2, # Trainer object to be used (default: Trainer())\n",
        "    context_length=dataset.metadata.prediction_length, # Number of steps to unroll the RNN for before computing predictions (default: None, in which case context_length = prediction_length)\n",
        "    num_layers=3, # Number of RNN layers (default: 2)\n",
        "    num_cells=40, # Number of RNN cells for each layer (default: 40)\n",
        "    cell_type='lstm', # Type of recurrent cells to use (available: ‘lstm’ or ‘gru’; default: ‘lstm’)\n",
        "    dropout_rate=0.1, # Dropout regularization parameter (default: 0.1)\n",
        "    use_feat_dynamic_real=False, # Whether to use the feat_dynamic_real field from the data (default: False)\n",
        "    use_feat_static_cat=True, # Whether to use the feat_static_cat field from the data (default: False)\n",
        "    use_feat_static_real=False, # Whether to use the feat_static_real field from the data (default: False)\n",
        "    cardinality=[321], # Number of values of each categorical feature. This must be set if use_feat_static_cat == True (default: None)\n",
        "    embedding_dimension=[20], # Dimension of the embeddings for categorical features (default: [min(50, (cat+1)//2) for cat in cardinality])\n",
        "    distr_output = GaussianOutput(), # Distribution to use to evaluate observations and sample predictions (default: StudentTOutput())\n",
        "    scaling=True, # Whether to automatically scale the target values (default: true)\n",
        "    lags_seq=None, # Indices of the lagged target values to use as inputs of the RNN (default: None, in which case these are automatically determined based on freq)\n",
        "    time_features=None, # Time features to use as inputs of the RNN (default: None, in which case these are automatically determined based on freq)\n",
        "    num_parallel_samples=1024, # Number of evaluation samples per time series to increase parallelism during inference. This is a model optimization that does not affect the accuracy (default: 100)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_ENJz7gkcc",
        "colab_type": "code",
        "outputId": "33009d07-2541-402d-a766-ccbb1dc06883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictor2 = estimator2.train(dataset.train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=1/100, avg_epoch_loss=7.09]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=2/100, avg_epoch_loss=7.29]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=3/100, avg_epoch_loss=7.02]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=4/100, avg_epoch_loss=6.29]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=5/100, avg_epoch_loss=6.05]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=6/100, avg_epoch_loss=5.85]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=7/100, avg_epoch_loss=5.91]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=8/100, avg_epoch_loss=5.75]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=9/100, avg_epoch_loss=5.73]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=10/100, avg_epoch_loss=5.97]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.05s/it, epoch=11/100, avg_epoch_loss=6.21]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.08s/it, epoch=12/100, avg_epoch_loss=5.82]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=13/100, avg_epoch_loss=5.62]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=14/100, avg_epoch_loss=5.61]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=15/100, avg_epoch_loss=5.9]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=16/100, avg_epoch_loss=5.55]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.10s/it, epoch=17/100, avg_epoch_loss=5.43]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=18/100, avg_epoch_loss=5.45]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.08s/it, epoch=19/100, avg_epoch_loss=5.46]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.08s/it, epoch=20/100, avg_epoch_loss=5.39]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.10s/it, epoch=21/100, avg_epoch_loss=5.41]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.08s/it, epoch=22/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.07s/it, epoch=23/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=24/100, avg_epoch_loss=5.5]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.10s/it, epoch=25/100, avg_epoch_loss=5.48]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=26/100, avg_epoch_loss=5.36]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=27/100, avg_epoch_loss=5.35]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.07s/it, epoch=28/100, avg_epoch_loss=5.43]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=29/100, avg_epoch_loss=5.33]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=30/100, avg_epoch_loss=5.53]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=31/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=32/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=33/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=34/100, avg_epoch_loss=5.34]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=35/100, avg_epoch_loss=5.35]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.07s/it, epoch=36/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=37/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=38/100, avg_epoch_loss=5.37]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=39/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=40/100, avg_epoch_loss=5.43]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=41/100, avg_epoch_loss=5.33]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=42/100, avg_epoch_loss=5.26]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=43/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=44/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=45/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=46/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=47/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=48/100, avg_epoch_loss=5.26]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.11s/it, epoch=49/100, avg_epoch_loss=5.37]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=50/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=51/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=52/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=53/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=54/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.08s/it, epoch=55/100, avg_epoch_loss=5.38]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=56/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=57/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=58/100, avg_epoch_loss=5.21]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=59/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=60/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=61/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=62/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.09s/it, epoch=63/100, avg_epoch_loss=5.32]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=64/100, avg_epoch_loss=5.35]\n",
            "100%|██████████| 20/20 [00:41<00:00,  2.10s/it, epoch=65/100, avg_epoch_loss=5.25]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=66/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=67/100, avg_epoch_loss=5.18]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=68/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=69/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=70/100, avg_epoch_loss=5.29]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=71/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=72/100, avg_epoch_loss=5.14]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=73/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=74/100, avg_epoch_loss=5.22]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.20s/it, epoch=75/100, avg_epoch_loss=5.24]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.18s/it, epoch=76/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 20/20 [00:44<00:00,  2.22s/it, epoch=77/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:44<00:00,  2.21s/it, epoch=78/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=79/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=80/100, avg_epoch_loss=5.27]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.19s/it, epoch=81/100, avg_epoch_loss=5.23]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=82/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=83/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.18s/it, epoch=84/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=85/100, avg_epoch_loss=5.2]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=86/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.12s/it, epoch=87/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.17s/it, epoch=88/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=89/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=90/100, avg_epoch_loss=5.16]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=91/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=92/100, avg_epoch_loss=5.28]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.18s/it, epoch=93/100, avg_epoch_loss=5.19]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.13s/it, epoch=94/100, avg_epoch_loss=5.12]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=95/100, avg_epoch_loss=5.15]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.14s/it, epoch=96/100, avg_epoch_loss=5.15]\n",
            "100%|██████████| 20/20 [00:42<00:00,  2.15s/it, epoch=97/100, avg_epoch_loss=5.12]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.16s/it, epoch=98/100, avg_epoch_loss=5.17]\n",
            "100%|██████████| 20/20 [00:43<00:00,  2.15s/it, epoch=99/100, avg_epoch_loss=5.15]\n",
            "100%|██████████| 20/20 [00:44<00:00,  2.21s/it, epoch=100/100, avg_epoch_loss=5.15]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg4L1P7JvTPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJkgiW33vXFP",
        "colab": {}
      },
      "source": [
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=dataset.train,  # test dataset\n",
        "    predictor=predictor2,  # predictor\n",
        "    num_samples=300,  # number of sample paths we want for evaluation\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ylnH8_tJvXFZ",
        "colab": {}
      },
      "source": [
        "# dataset에 있는 데이터 개수 만큼이 만들어짐\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8105bd15-c2c8-4377-bc0d-b92b9df9a3e6",
        "id": "5RYqB695vXFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
        "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(dataset.train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running evaluation: 100%|██████████| 321/321 [00:00<00:00, 3336.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1904780d-4a61-4f11-e243-1a3fbd617d96",
        "id": "5qq-rJwmvXFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "# sampling 결과다 보니, sample paths를 다시 만들 때마다 값이 조금씩 달라지기는 함\n",
        "## 어느 시점의 값을 결과로 사용해야 하는 걸까???????????\n",
        "print(json.dumps(agg_metrics, indent=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"MSE\": 974462.2403720074,\n",
            "    \"abs_error\": 1158564.3923244476,\n",
            "    \"abs_target_sum\": 16669730.0,\n",
            "    \"abs_target_mean\": 2163.7759605399806,\n",
            "    \"seasonal_error\": 189.65640599692924,\n",
            "    \"MASE\": 0.7406150553997146,\n",
            "    \"MAPE\": 0.09075030721376187,\n",
            "    \"sMAPE\": 0.12211189502771007,\n",
            "    \"OWA\": NaN,\n",
            "    \"MSIS\": 7.301125256926607,\n",
            "    \"QuantileLoss[0.1]\": 469995.99455171084,\n",
            "    \"Coverage[0.1]\": 0.08372274143302186,\n",
            "    \"QuantileLoss[0.5]\": 1158564.381817538,\n",
            "    \"Coverage[0.5]\": 0.5507528556593979,\n",
            "    \"QuantileLoss[0.9]\": 603593.3619128703,\n",
            "    \"Coverage[0.9]\": 0.9048546209761166,\n",
            "    \"RMSE\": 987.1485401762023,\n",
            "    \"NRMSE\": 0.45621568876745205,\n",
            "    \"ND\": 0.06950108923926468,\n",
            "    \"wQuantileLoss[0.1]\": 0.028194577509756357,\n",
            "    \"wQuantileLoss[0.5]\": 0.06950108860896595,\n",
            "    \"wQuantileLoss[0.9]\": 0.03620894651040361,\n",
            "    \"mean_wQuantileLoss\": 0.044634870876375306,\n",
            "    \"MAE_Coverage\": 0.02396157840083087\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfEs_W0WvTLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74-kMUeLvTIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSTcVrBtvP51",
        "colab_type": "text"
      },
      "source": [
        "DeepFactor 실험 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOT3XyhZCZ1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "from mxnet.gluon import HybridBlock\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "# First-party imports\n",
        "from gluonts.block.feature import FeatureEmbedder\n",
        "from gluonts.core.component import validated\n",
        "from gluonts.model.common import Tensor\n",
        "\n",
        "\n",
        "class DeepFactorNetworkBase(HybridBlock):\n",
        "    def __init__(\n",
        "        self,\n",
        "        global_model: HybridBlock,\n",
        "        local_model: HybridBlock,\n",
        "        embedder: FeatureEmbedder,\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.global_model = global_model\n",
        "        self.local_model = local_model\n",
        "        self.embedder = embedder\n",
        "        with self.name_scope():\n",
        "            self.loading = nn.Dense(\n",
        "                units=global_model.num_output, use_bias=False\n",
        "            )\n",
        "\n",
        "    def assemble_features(\n",
        "        self,\n",
        "        F,\n",
        "        feat_static_cat: Tensor,  # (batch_size, 1)\n",
        "        time_feat: Tensor,  # (batch_size, history_length, num_features)\n",
        "    ) -> Tensor:  # (batch_size, history_length, num_features)\n",
        "        # todo: this is shared by more than one places, and should be a general routine\n",
        "\n",
        "        embedded_cat = self.embedder(\n",
        "            feat_static_cat\n",
        "        )  # (batch_size, num_features * embedding_size)\n",
        "\n",
        "        # a workaround when you wish to repeat without knowing the number\n",
        "        # of repeats\n",
        "        helper_ones = F.ones_like(\n",
        "            F.slice_axis(time_feat, axis=2, begin=-1, end=None)\n",
        "        )\n",
        "        # (batch_size, history_length, num_features * embedding_size)\n",
        "        repeated_cat = F.batch_dot(\n",
        "            helper_ones, F.expand_dims(embedded_cat, axis=1)\n",
        "        )\n",
        "\n",
        "        # putting together all the features\n",
        "        input_feat = F.concat(repeated_cat, time_feat, dim=2)\n",
        "        return embedded_cat, input_feat\n",
        "\n",
        "    def compute_global_local(\n",
        "        self,\n",
        "        F,\n",
        "        feat_static_cat: Tensor,  # (batch_size, 1)\n",
        "        time_feat: Tensor,  # (batch_size, history_length, num_features)\n",
        "    ) -> (Tensor, Tensor):  # both of size (batch_size, history_length, 1)\n",
        "\n",
        "        cat, local_input = self.assemble_features(\n",
        "            F, feat_static_cat, time_feat\n",
        "        )\n",
        "        loadings = self.loading(cat)  # (batch_size, num_factors)\n",
        "        global_factors = self.global_model(\n",
        "            time_feat\n",
        "        )  # (batch_size, history_length, num_factors)\n",
        "\n",
        "        fixed_effect = F.batch_dot(\n",
        "            global_factors, loadings.expand_dims(axis=2)\n",
        "        )  # (batch_size, history_length, 1)\n",
        "        random_effect = F.log(\n",
        "            F.exp(self.local_model(local_input)) + 1.0\n",
        "        )  # (batch_size, history_length, 1)\n",
        "        return F.exp(fixed_effect), random_effect\n",
        "\n",
        "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def negative_normal_likelihood(self, F, y, mu, sigma):\n",
        "        return (\n",
        "            F.log(sigma)\n",
        "            + 0.5 * math.log(2 * math.pi)\n",
        "            + 0.5 * F.square((y - mu) / sigma)\n",
        "        )\n",
        "\n",
        "\n",
        "class DeepFactorTrainingNetwork(DeepFactorNetworkBase):\n",
        "    def hybrid_forward(\n",
        "        self,\n",
        "        F,\n",
        "        feat_static_cat: Tensor,  # (batch_size, 1)\n",
        "        past_time_feat: Tensor,\n",
        "        # (batch_size, history_length, num_features)\n",
        "        past_target: Tensor,  # (batch_size, history_length)\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        F\n",
        "            Function space\n",
        "        feat_static_cat\n",
        "            Shape: (batch_size, 1)\n",
        "        past_time_feat\n",
        "            Shape: (batch_size, history_length, num_features)\n",
        "        past_target\n",
        "            Shape: (batch_size, history_length)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor\n",
        "            A batch of negative log likelihoods.\n",
        "        \"\"\"\n",
        "\n",
        "        fixed_effect, random_effect = self.compute_global_local(\n",
        "            F, feat_static_cat, past_time_feat\n",
        "        )\n",
        "\n",
        "        loss = self.negative_normal_likelihood(\n",
        "            F, past_target.expand_dims(axis=2), fixed_effect, random_effect\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "\n",
        "class DeepFactorPredictionNetwork(DeepFactorNetworkBase):\n",
        "    @validated()\n",
        "    def __init__(\n",
        "        self, prediction_len: int, num_parallel_samples: int, **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "        self.prediction_len = prediction_len\n",
        "        self.num_parallel_samples = num_parallel_samples\n",
        "\n",
        "    def hybrid_forward(\n",
        "        self,\n",
        "        F,\n",
        "        feat_static_cat: Tensor,\n",
        "        past_time_feat: Tensor,\n",
        "        future_time_feat: Tensor,\n",
        "        past_target: Tensor,\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        F\n",
        "            Function space\n",
        "        feat_static_cat\n",
        "            Shape: (batch_size, 1)\n",
        "        past_time_feat\n",
        "            Shape: (batch_size, history_length, num_features)\n",
        "        future_time_feat\n",
        "            Shape: (batch_size, prediction_length, num_features)\n",
        "        past_target\n",
        "            Shape: (batch_size, history_length)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor\n",
        "            Samples of shape (batch_size, num_samples, prediction_length).\n",
        "        \"\"\"\n",
        "        time_feat = F.concat(past_time_feat, future_time_feat, dim=1)\n",
        "        fixed_effect, random_effect = self.compute_global_local(\n",
        "            F, feat_static_cat, time_feat\n",
        "        )\n",
        "\n",
        "        samples = F.concat(\n",
        "            *[\n",
        "                F.sample_normal(fixed_effect, random_effect)\n",
        "                for _ in range(self.num_parallel_samples)\n",
        "            ],\n",
        "            dim=2,\n",
        "        )  # (batch_size, train_len + prediction_len, num_samples)\n",
        "        pred_samples = F.slice_axis(\n",
        "            samples, axis=1, begin=-self.prediction_len, end=None\n",
        "        )  # (batch_size, prediction_len, num_samples)\n",
        "\n",
        "        return pred_samples.swapaxes(1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--4ZtaKXCd0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "# First-party imports\n",
        "from gluonts import transform\n",
        "from gluonts.block.feature import FeatureEmbedder\n",
        "from gluonts.core.component import validated\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.distribution import DistributionOutput, StudentTOutput\n",
        "\n",
        "from gluonts.model.deep_factor.RNNModel import RNNModel\n",
        "from gluonts.model.deep_factor._network import (\n",
        "    DeepFactorTrainingNetwork,\n",
        "    DeepFactorPredictionNetwork,\n",
        ")\n",
        "from gluonts.model.estimator import GluonEstimator\n",
        "from gluonts.model.predictor import Predictor, RepresentableBlockPredictor\n",
        "from gluonts.time_feature import time_features_from_frequency_str\n",
        "from gluonts.trainer import Trainer\n",
        "from gluonts.transform import (\n",
        "    AddTimeFeatures,\n",
        "    AsNumpyArray,\n",
        "    Chain,\n",
        "    SetFieldIfNotPresent,\n",
        "    TestSplitSampler,\n",
        "    Transformation,\n",
        "    ExpectedNumInstanceSampler,\n",
        ")\n",
        "\n",
        "\n",
        "# Third-party imports\n",
        "\n",
        "class custom_DeepFactorEstimator(GluonEstimator):\n",
        "    \"\"\"\n",
        "    DeepFactorEstimator is an implementation of the 2019 ICML paper \"Deep Factors for Forecasting\"\n",
        "    https://arxiv.org/abs/1905.12417.  It uses a global RNN model to learn patterns across multiple related time series\n",
        "    and an arbitrary local model to model the time series on a per time series basis.  In the current implementation,\n",
        "    the local model is a RNN (DF-RNN).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq\n",
        "        Time series frequency.\n",
        "    prediction_length\n",
        "        Prediction length.\n",
        "    num_hidden_global\n",
        "        Number of units per hidden layer for the global RNN model (default: 50).\n",
        "    num_layers_global\n",
        "        Number of hidden layers for the global RNN model (default: 1).\n",
        "    num_factors\n",
        "        Number of global factors (default: 10).\n",
        "    num_hidden_local\n",
        "        Number of units per hidden layer for the local RNN model (default: 5).\n",
        "    num_layers_local\n",
        "        Number of hidden layers for the global local model (default: 1).\n",
        "    cell_type\n",
        "        Type of recurrent cells to use (available: 'lstm' or 'gru';\n",
        "        default: 'lstm').\n",
        "    trainer\n",
        "        Trainer object to be used (default: Trainer()).\n",
        "    context_length\n",
        "        Training length (default: None, in which case context_length = prediction_length).\n",
        "    num_parallel_samples\n",
        "        Number of evaluation samples per time series to increase parallelism during inference.\n",
        "        This is a model optimization that does not affect the accuracy (default: 100).\n",
        "    cardinality\n",
        "        List consisting of the number of time series (default: list([1]).\n",
        "    embedding_dimension\n",
        "        Dimension of the embeddings for categorical features (the same\n",
        "        dimension is used for all embeddings, default: 10).\n",
        "    distr_output\n",
        "        Distribution to use to evaluate observations and sample predictions\n",
        "        (default: StudentTOutput()).\n",
        "    \"\"\"\n",
        "\n",
        "    @validated()\n",
        "    def __init__(\n",
        "        self,\n",
        "        freq: str,\n",
        "        prediction_length: int,\n",
        "        num_hidden_global: int = 50,\n",
        "        num_layers_global: int = 1,\n",
        "        num_factors: int = 10,\n",
        "        num_hidden_local: int = 5,\n",
        "        num_layers_local: int = 1,\n",
        "        cell_type: str = \"lstm\",\n",
        "        trainer: Trainer = Trainer(),\n",
        "        context_length: Optional[int] = None,\n",
        "        num_parallel_samples: int = 100,\n",
        "        cardinality: List[int] = list([1]),\n",
        "        embedding_dimension: int = 10,\n",
        "        distr_output: DistributionOutput = StudentTOutput(),\n",
        "    ) -> None:\n",
        "        super().__init__(trainer=trainer)\n",
        "\n",
        "        assert (\n",
        "            prediction_length > 0\n",
        "        ), \"The value of `prediction_length` should be > 0\"\n",
        "        assert (\n",
        "            context_length is None or context_length > 0\n",
        "        ), \"The value of `context_length` should be > 0\"\n",
        "        assert num_layers_global > 0, \"The value of `num_layers` should be > 0\"\n",
        "        assert num_hidden_global > 0, \"The value of `num_hidden` should be > 0\"\n",
        "        assert num_factors > 0, \"The value of `num_factors` should be > 0\"\n",
        "        assert (\n",
        "            num_hidden_local > 0\n",
        "        ), \"The value of `num_hidden_local` should be > 0\"\n",
        "        assert (\n",
        "            num_layers_local > 0\n",
        "        ), \"The value of `num_layers_local` should be > 0\"\n",
        "        assert all(\n",
        "            [c > 0 for c in cardinality]\n",
        "        ), \"Elements of `cardinality` should be > 0\"\n",
        "        assert (\n",
        "            embedding_dimension > 0\n",
        "        ), \"The value of `embedding_dimension` should be > 0\"\n",
        "        assert (\n",
        "            num_parallel_samples > 0\n",
        "        ), \"The value of `num_parallel_samples` should be > 0\"\n",
        "\n",
        "        self.freq = freq\n",
        "        self.context_length = (\n",
        "            context_length if context_length is not None else prediction_length\n",
        "        )\n",
        "        self.prediction_length = prediction_length\n",
        "        self.distr_output = distr_output\n",
        "        self.num_parallel_samples = num_parallel_samples\n",
        "        self.cardinality = cardinality\n",
        "        self.embedding_dimensions = [embedding_dimension for _ in cardinality]\n",
        "\n",
        "        self.global_model = RNNModel(\n",
        "            mode=cell_type,\n",
        "            num_hidden=num_hidden_global,\n",
        "            num_layers=num_layers_global,\n",
        "            num_output=num_factors,\n",
        "        )\n",
        "\n",
        "        # TODO: Allow the local model to be defined as an arbitrary local model, e.g. DF-GP and DF-LDS\n",
        "        self.local_model = RNNModel(\n",
        "            mode=cell_type,\n",
        "            num_hidden=num_hidden_local,\n",
        "            num_layers=num_layers_local,\n",
        "            num_output=1,\n",
        "        )\n",
        "\n",
        "    def create_transformation(self) -> Transformation:\n",
        "        return Chain(\n",
        "            trans=[\n",
        "                AsNumpyArray(field=FieldName.TARGET, expected_ndim=1),\n",
        "                AddTimeFeatures(\n",
        "                    start_field=FieldName.START,\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    output_field=FieldName.FEAT_TIME,\n",
        "                    time_features=time_features_from_frequency_str(self.freq),\n",
        "                    pred_length=self.prediction_length,\n",
        "                ),\n",
        "                SetFieldIfNotPresent(\n",
        "                    field=FieldName.FEAT_STATIC_CAT, value=[0.0]\n",
        "                ),\n",
        "                AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\n",
        "                transform.InstanceSplitter(\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    is_pad_field=FieldName.IS_PAD,\n",
        "                    start_field=FieldName.START,\n",
        "                    forecast_start_field=FieldName.FORECAST_START,\n",
        "                    train_sampler=ExpectedNumInstanceSampler(num_instances=1),\n",
        "                    #train_sampler=TestSplitSampler(),\n",
        "                    time_series_fields=[FieldName.FEAT_TIME],\n",
        "                    past_length=self.context_length,\n",
        "                    future_length=self.prediction_length,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def create_training_network(self) -> DeepFactorTrainingNetwork:\n",
        "        return DeepFactorTrainingNetwork(\n",
        "            embedder=FeatureEmbedder(\n",
        "                cardinalities=self.cardinality,\n",
        "                embedding_dims=self.embedding_dimensions,\n",
        "            ),\n",
        "            global_model=self.global_model,\n",
        "            local_model=self.local_model,\n",
        "        )\n",
        "\n",
        "    def create_predictor(\n",
        "        self,\n",
        "        transformation: Transformation,\n",
        "        trained_network: DeepFactorTrainingNetwork,\n",
        "    ) -> Predictor:\n",
        "        prediction_net = DeepFactorPredictionNetwork(\n",
        "            embedder=trained_network.embedder,\n",
        "            global_model=trained_network.global_model,\n",
        "            local_model=trained_network.local_model,\n",
        "            prediction_len=self.prediction_length,\n",
        "            num_parallel_samples=self.num_parallel_samples,\n",
        "            params=trained_network.collect_params(),\n",
        "        )\n",
        "\n",
        "        return RepresentableBlockPredictor(\n",
        "            input_transform=transformation,\n",
        "            prediction_net=prediction_net,\n",
        "            batch_size=self.trainer.batch_size,\n",
        "            freq=self.freq,\n",
        "            prediction_length=self.prediction_length,\n",
        "            ctx=self.trainer.ctx,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwUuzF6ZvpBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from gluonts.model.deep_factor import DeepFactorEstimator\n",
        "from gluonts.distribution.student_t import StudentTOutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQY8E9Xgord",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.trainer.html\n",
        "deepfactor_trainer=Trainer(\n",
        "    ctx = 'gpu',\n",
        "    epochs=100, # Number of epochs that the network will train (default: 100).\n",
        "    batch_size=64,# Number of examples in each batch (default: 32).\n",
        "    num_batches_per_epoch=78, # Number of batches at each epoch (default: 50).\n",
        "    learning_rate=1e-3, # Initial learning rate (default:  1e−3 ).\n",
        "    learning_rate_decay_factor=0.5, # Factor (between 0 and 1) by which to decrease the learning rate (default: 0.5).\n",
        "    patience = 10, # The patience to observe before reducing the learning rate, nonnegative integer (default: 10).\n",
        "    minimum_learning_rate=5e-5, #  Lower bound for the learning rate (default:  5⋅1e−5 ).\n",
        "    clip_gradient = 10, # Maximum value of gradient. The gradient is clipped if it is too large (default: 10).\n",
        "    weight_decay=1e-8, # The weight decay (or L2 regularization) coefficient. Modifies objective by adding a penalty for having large weights (default  10−8 ).\n",
        "    init='xavier', # Initializer of the weights of the network (default: “xavier”).\n",
        "    hybridize=True, ## ???????\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tveDHK_2wVyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/_modules/gluonts/model/deep_factor/_estimator.html#DeepFactorEstimator\n",
        "DF_estimator = custom_DeepFactorEstimator(\n",
        "    freq=dataset.metadata.freq, # Time series frequency\n",
        "    prediction_length=dataset.metadata.prediction_length, # Prediction length.\n",
        "    num_hidden_global=50, # Number of units per hidden layer for the global RNN model (default: 50).\n",
        "    num_layers_global=1, # Number of hidden layers for the global RNN model (default: 1).\n",
        "    num_factors=10, # Number of global factors (default: 10).\n",
        "    num_hidden_local=5, # Number of units per hidden layer for the local RNN model (default: 5).\n",
        "    num_layers_local=1, # Number of hidden layers for the global local model (default: 1).\n",
        "    cell_type='lstm', # Type of recurrent cells to use (available: ‘lstm’ or ‘gru’; default: ‘lstm’).\n",
        "    trainer = deepfactor_trainer, # Trainer object to be used (default: Trainer()).\n",
        "    context_length=None, # Training length (default: None, in which case context_length = prediction_length).\n",
        "    num_parallel_samples=1024, # Number of evaluation samples per time series to increase parallelism during inference. This is a model optimization that does not affect the accuracy (default: 100).\n",
        "    cardinality=[1], # List consisting of the number of time series (default: list([1]).\n",
        "    embedding_dimension=10, # Dimension of the embeddings for categorical features (the same dimension is used for all embeddings, default: 10).\n",
        "    distr_output=StudentTOutput(), # Distribution to use to evaluate observations and sample predictions (default: StudentTOutput()).\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr9KotzxyU4M",
        "colab_type": "code",
        "outputId": "a8be1ae2-1068-40b2-a785-797051ce3587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DF_predictor = DF_estimator.train(dataset.train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:24<00:00,  3.19it/s, epoch=1/100, avg_epoch_loss=1.56e+8]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=2/100, avg_epoch_loss=5.6e+7] \n",
            "100%|██████████| 78/78 [00:25<00:00,  3.02it/s, epoch=3/100, avg_epoch_loss=2.42e+7]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=4/100, avg_epoch_loss=8.14e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=5/100, avg_epoch_loss=8.96e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=6/100, avg_epoch_loss=6.21e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.00it/s, epoch=7/100, avg_epoch_loss=3.59e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=8/100, avg_epoch_loss=1.26e+6]\n",
            "100%|██████████| 78/78 [00:26<00:00,  2.98it/s, epoch=9/100, avg_epoch_loss=2.98e+6]\n",
            "100%|██████████| 78/78 [00:26<00:00,  2.94it/s, epoch=10/100, avg_epoch_loss=2.22e+6]\n",
            "100%|██████████| 78/78 [00:26<00:00,  3.00it/s, epoch=11/100, avg_epoch_loss=1.94e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.08it/s, epoch=12/100, avg_epoch_loss=2.23e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=13/100, avg_epoch_loss=1.37e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=14/100, avg_epoch_loss=1.26e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=15/100, avg_epoch_loss=1.61e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.02it/s, epoch=16/100, avg_epoch_loss=9.01e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.02it/s, epoch=17/100, avg_epoch_loss=4.01e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=18/100, avg_epoch_loss=6.78e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.03it/s, epoch=19/100, avg_epoch_loss=7.2e+5] \n",
            "100%|██████████| 78/78 [00:25<00:00,  3.05it/s, epoch=20/100, avg_epoch_loss=8.19e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.11it/s, epoch=21/100, avg_epoch_loss=6.96e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.01it/s, epoch=22/100, avg_epoch_loss=8.08e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.02it/s, epoch=23/100, avg_epoch_loss=6.53e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=24/100, avg_epoch_loss=4.72e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.07it/s, epoch=25/100, avg_epoch_loss=4.27e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=26/100, avg_epoch_loss=4.29e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=27/100, avg_epoch_loss=4.7e+5] \n",
            "100%|██████████| 78/78 [00:24<00:00,  3.16it/s, epoch=28/100, avg_epoch_loss=8.89e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.03it/s, epoch=29/100, avg_epoch_loss=6.69e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=30/100, avg_epoch_loss=1.36e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.07it/s, epoch=31/100, avg_epoch_loss=8.32e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.05it/s, epoch=32/100, avg_epoch_loss=4.86e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=33/100, avg_epoch_loss=8.85e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.00it/s, epoch=34/100, avg_epoch_loss=1.11e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=35/100, avg_epoch_loss=4.47e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.08it/s, epoch=36/100, avg_epoch_loss=1.06e+6]\n",
            "100%|██████████| 78/78 [00:24<00:00,  3.13it/s, epoch=37/100, avg_epoch_loss=9.2e+5] \n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=38/100, avg_epoch_loss=9.72e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=39/100, avg_epoch_loss=6.49e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.07it/s, epoch=40/100, avg_epoch_loss=1.76e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.08it/s, epoch=41/100, avg_epoch_loss=1.27e+6]\n",
            "100%|██████████| 78/78 [00:24<00:00,  3.15it/s, epoch=42/100, avg_epoch_loss=9.13e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=43/100, avg_epoch_loss=1.04e+6]\n",
            "100%|██████████| 78/78 [00:24<00:00,  3.13it/s, epoch=44/100, avg_epoch_loss=8.89e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=45/100, avg_epoch_loss=8.93e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.08it/s, epoch=46/100, avg_epoch_loss=7.41e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=47/100, avg_epoch_loss=3.84e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=48/100, avg_epoch_loss=1.06e+6]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=49/100, avg_epoch_loss=6.47e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.04it/s, epoch=50/100, avg_epoch_loss=5e+5]   \n",
            "100%|██████████| 78/78 [00:24<00:00,  3.12it/s, epoch=51/100, avg_epoch_loss=5.24e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.11it/s, epoch=52/100, avg_epoch_loss=7.48e+5]\n",
            "100%|██████████| 78/78 [00:24<00:00,  3.12it/s, epoch=53/100, avg_epoch_loss=9.03e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.10it/s, epoch=54/100, avg_epoch_loss=3.62e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.08it/s, epoch=55/100, avg_epoch_loss=8.51e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.03it/s, epoch=56/100, avg_epoch_loss=3.85e+5]\n",
            "100%|██████████| 78/78 [00:24<00:00,  3.13it/s, epoch=57/100, avg_epoch_loss=7.11e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.12it/s, epoch=58/100, avg_epoch_loss=6.02e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.09it/s, epoch=59/100, avg_epoch_loss=6.23e+5]\n",
            "100%|██████████| 78/78 [00:25<00:00,  3.06it/s, epoch=60/100, avg_epoch_loss=8.88e+5]\n",
            "100%|██████████| 78/78 [00:26<00:00,  3.00it/s, epoch=61/100, avg_epoch_loss=9.75e+5]\n",
            " 38%|███▊      | 30/78 [00:10<00:16,  2.98it/s, epoch=62/100, avg_epoch_loss=9.02e+5]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abttE0EjyX5d",
        "colab": {}
      },
      "source": [
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=dataset.train,  # test dataset\n",
        "    predictor=DF_predictor,  # predictor\n",
        "    num_samples=300,  # number of sample paths we want for evaluation\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdD21vaxyX5l",
        "colab": {}
      },
      "source": [
        "# dataset에 있는 데이터 개수 만큼이 만들어짐\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "414c1ad6-01c0-4ab2-ef80-a167245fc64e",
        "id": "bdzg2PciyX5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
        "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(dataset.train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running evaluation: 100%|██████████| 321/321 [00:00<00:00, 3646.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "64ecca83-d854-414c-8fd8-a57622d246af",
        "id": "_KH2t6dKyX5t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "# sampling 결과다 보니, sample paths를 다시 만들 때마다 값이 조금씩 달라지기는 함\n",
        "## 어느 시점의 값을 결과로 사용해야 하는 걸까???????????\n",
        "print(json.dumps(agg_metrics, indent=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"MSE\": 125489484.04337032,\n",
            "    \"abs_error\": 16843198.954589844,\n",
            "    \"abs_target_sum\": 16669730.0,\n",
            "    \"abs_target_mean\": 2163.7759605399806,\n",
            "    \"seasonal_error\": 189.65640599692924,\n",
            "    \"MASE\": 36.17634592559786,\n",
            "    \"MAPE\": 6.5716509960768015,\n",
            "    \"sMAPE\": 1.0317444022111208,\n",
            "    \"OWA\": NaN,\n",
            "    \"MSIS\": 1367.7016299807576,\n",
            "    \"QuantileLoss[0.1]\": 10851790.0078125,\n",
            "    \"Coverage[0.1]\": 0.7403946002076843,\n",
            "    \"QuantileLoss[0.5]\": 16843198.8069458,\n",
            "    \"Coverage[0.5]\": 0.751817237798546,\n",
            "    \"QuantileLoss[0.9]\": 22081073.529064942,\n",
            "    \"Coverage[0.9]\": 0.7599948078920042,\n",
            "    \"RMSE\": 11202.208891257578,\n",
            "    \"NRMSE\": 5.177157476350747,\n",
            "    \"ND\": 1.010406224611307,\n",
            "    \"wQuantileLoss[0.1]\": 0.6509877489204984,\n",
            "    \"wQuantileLoss[0.5]\": 1.0104062157542923,\n",
            "    \"wQuantileLoss[0.9]\": 1.3246209464139456,\n",
            "    \"mean_wQuantileLoss\": 0.9953383036962453,\n",
            "    \"MAE_Coverage\": 0.34407234337140874\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLYu-dadyjok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}