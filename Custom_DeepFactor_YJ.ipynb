{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Custom_DeepFactor_YJ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/GluonTS/blob/master/Custom_DeepFactor_YJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z9AGzd34Pq3",
        "colab_type": "code",
        "outputId": "0e22b844-9dd8-486e-e3af-9560a1a8d825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "pip install --upgrade mxnet==1.6 gluonts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet==1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 62kB/s \n",
            "\u001b[?25hCollecting gluonts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/07/5a63f7d645761982743d375fc816120b680e0de13ac139829e509b3206fc/gluonts-0.5.0-py3-none-any.whl (419kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 52.2MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: holidays<0.10,>=0.9 in /usr/local/lib/python3.6/dist-packages (from gluonts) (0.9.12)\n",
            "Collecting ujson~=1.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas~=1.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (1.0.3)\n",
            "Collecting pydantic~=1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/c9/7d664fbe54863b92cea790c7305915888c2f13a68a754893d8291bab0d0d/pydantic-1.5.1-cp36-cp36m-manylinux2014_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm~=4.23 in /usr/local/lib/python3.6/dist-packages (from gluonts) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from holidays<0.10,>=0.9->gluonts) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from holidays<0.10,>=0.9->gluonts) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0->gluonts) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic~=1.1->gluonts) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->gluonts) (0.10.0)\n",
            "Building wheels for collected packages: ujson\n",
            "  Building wheel for ujson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ujson: filename=ujson-1.35-cp36-cp36m-linux_x86_64.whl size=68011 sha256=27f1eeb97f4b0dc1840660044f318019953436a31b09de20d87392eaa5ad74eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "Successfully built ujson\n",
            "Installing collected packages: graphviz, mxnet, ujson, pydantic, gluonts\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluonts-0.5.0 graphviz-0.8.4 mxnet-1.6.0 pydantic-1.5.1 ujson-1.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WG_vAK55EMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Third-party imports\n",
        "%matplotlib inline\n",
        "import mxnet as mx\n",
        "from mxnet import gluon\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "#import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDklUj_75EJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
        "#from gluonts.dataset.util import to_pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gmAIFj5IJM",
        "colab_type": "code",
        "outputId": "b3ffe761-12d2-419e-bdd8-e22feaf7f3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataset = get_dataset('electricity', regenerate=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving time-series into /root/.mxnet/gluon-ts/datasets/electricity/train/data.json\n",
            "saving time-series into /root/.mxnet/gluon-ts/datasets/electricity/test/data.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v0x6H1oAZRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.trainer.html\n",
        "deepfactor_trainer=Trainer(\n",
        "    ctx = 'cpu',\n",
        "    epochs=100, # (default: 100).\n",
        "    batch_size=32,# (default: 32).\n",
        "    num_batches_per_epoch=50, # (default: 50).\n",
        "    learning_rate=0.001, # (default:  10^−3 ).\n",
        "    learning_rate_decay_factor=0.5, # (default: 0.5).\n",
        "    patience = 10, # (default: 10).\n",
        "    minimum_learning_rate=5e-05, # (default:  5⋅10^−5 ).\n",
        "    clip_gradient = 10.0, # (default: 10).\n",
        "    weight_decay=1e-08, #  (default  10^−8 ).\n",
        "    init='xavier', #  (default: “xavier”).\n",
        "    hybridize=True, \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yHVhJ_K-HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change only context_length\n",
        "DF_estimator = DeepFactorEstimator(\n",
        "    freq=dataset.metadata.freq, # Time series frequency\n",
        "    prediction_length=dataset.metadata.prediction_length, # Prediction length.\n",
        "    num_hidden_global=50, # (default: 50).\n",
        "    num_layers_global=1, # (default: 1).\n",
        "    num_factors=10, # (default: 10).\n",
        "    num_hidden_local=5, # (default: 5).\n",
        "    num_layers_local=1, # (default: 1).\n",
        "    cell_type='lstm', # (default: ‘lstm’).\n",
        "    trainer = deepfactor_trainer, # (default: Trainer()).\n",
        "    context_length=168, # (default: None, in which case context_length = prediction_length).\n",
        "    num_parallel_samples=100, # (default: 100).\n",
        "    cardinality=[int(dataset.metadata.feat_static_cat[0].cardinality)], # (default: list([1]).\n",
        "    embedding_dimension=10, # (default: 10).\n",
        "    #distr_output=StudentTOutput(), # (default: StudentTOutput()).\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CWa4kK1LWbI",
        "colab_type": "code",
        "outputId": "37ca52ef-d12f-47ac-a3c3-b3049c7ebda4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DF_predictor = DF_estimator.train(dataset.train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.25it/s, epoch=1/100, avg_epoch_loss=1.41e+8]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.26it/s, epoch=2/100, avg_epoch_loss=8.34e+7]\n",
            "100%|██████████| 50/50 [00:12<00:00,  4.00it/s, epoch=3/100, avg_epoch_loss=6.11e+7]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.22it/s, epoch=4/100, avg_epoch_loss=2.88e+7]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.19it/s, epoch=5/100, avg_epoch_loss=1.26e+7]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.21it/s, epoch=6/100, avg_epoch_loss=6.87e+6]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.35it/s, epoch=7/100, avg_epoch_loss=4.34e+6]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.37it/s, epoch=8/100, avg_epoch_loss=3.03e+6]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, epoch=9/100, avg_epoch_loss=1.68e+6]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, epoch=10/100, avg_epoch_loss=5.94e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.38it/s, epoch=11/100, avg_epoch_loss=4.87e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=12/100, avg_epoch_loss=4.01e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=13/100, avg_epoch_loss=4.22e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=14/100, avg_epoch_loss=3.25e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=15/100, avg_epoch_loss=2.76e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=16/100, avg_epoch_loss=2.44e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, epoch=17/100, avg_epoch_loss=2.21e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=18/100, avg_epoch_loss=2.14e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, epoch=19/100, avg_epoch_loss=1.75e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=20/100, avg_epoch_loss=1.55e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=21/100, avg_epoch_loss=1.4e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=22/100, avg_epoch_loss=1.22e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=23/100, avg_epoch_loss=1.19e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.36it/s, epoch=24/100, avg_epoch_loss=1.22e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=25/100, avg_epoch_loss=1.04e+5]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=26/100, avg_epoch_loss=9.48e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.37it/s, epoch=27/100, avg_epoch_loss=9.94e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=28/100, avg_epoch_loss=8.83e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=29/100, avg_epoch_loss=8.07e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=30/100, avg_epoch_loss=7.05e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=31/100, avg_epoch_loss=6.15e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=32/100, avg_epoch_loss=6.52e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, epoch=33/100, avg_epoch_loss=5.82e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=34/100, avg_epoch_loss=5.62e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=35/100, avg_epoch_loss=6.03e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=36/100, avg_epoch_loss=4.83e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=37/100, avg_epoch_loss=5.55e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.38it/s, epoch=38/100, avg_epoch_loss=5.24e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=39/100, avg_epoch_loss=4.75e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.47it/s, epoch=40/100, avg_epoch_loss=4.2e+4] \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=41/100, avg_epoch_loss=4.21e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=42/100, avg_epoch_loss=3.89e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=43/100, avg_epoch_loss=3.63e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=44/100, avg_epoch_loss=3.62e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=45/100, avg_epoch_loss=3.75e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=46/100, avg_epoch_loss=3.36e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=47/100, avg_epoch_loss=3.21e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=48/100, avg_epoch_loss=3.64e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=49/100, avg_epoch_loss=2.45e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.64it/s, epoch=50/100, avg_epoch_loss=3.15e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=51/100, avg_epoch_loss=3.3e+4] \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=52/100, avg_epoch_loss=2.57e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.41it/s, epoch=53/100, avg_epoch_loss=2.89e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.38it/s, epoch=54/100, avg_epoch_loss=2.58e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=55/100, avg_epoch_loss=3.35e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=56/100, avg_epoch_loss=2.18e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.47it/s, epoch=57/100, avg_epoch_loss=2.15e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=58/100, avg_epoch_loss=2.16e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=59/100, avg_epoch_loss=2.4e+4] \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, epoch=60/100, avg_epoch_loss=1.95e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.39it/s, epoch=61/100, avg_epoch_loss=1.95e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=62/100, avg_epoch_loss=2.08e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.47it/s, epoch=63/100, avg_epoch_loss=1.78e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=64/100, avg_epoch_loss=1.55e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=65/100, avg_epoch_loss=1.61e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=66/100, avg_epoch_loss=1.51e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=67/100, avg_epoch_loss=1.58e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s, epoch=68/100, avg_epoch_loss=1.61e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s, epoch=69/100, avg_epoch_loss=1.46e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s, epoch=70/100, avg_epoch_loss=1.95e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=71/100, avg_epoch_loss=1.45e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s, epoch=72/100, avg_epoch_loss=1.85e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s, epoch=73/100, avg_epoch_loss=1.36e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=74/100, avg_epoch_loss=1.67e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=75/100, avg_epoch_loss=1.58e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=76/100, avg_epoch_loss=1.31e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=77/100, avg_epoch_loss=1.4e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=78/100, avg_epoch_loss=1.4e+4] \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s, epoch=79/100, avg_epoch_loss=1.53e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s, epoch=80/100, avg_epoch_loss=1.58e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=81/100, avg_epoch_loss=1e+4]  \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s, epoch=82/100, avg_epoch_loss=1.01e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.51it/s, epoch=83/100, avg_epoch_loss=1.17e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.52it/s, epoch=84/100, avg_epoch_loss=1.02e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s, epoch=85/100, avg_epoch_loss=1.03e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.51it/s, epoch=86/100, avg_epoch_loss=1.13e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.49it/s, epoch=87/100, avg_epoch_loss=1.12e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.37it/s, epoch=88/100, avg_epoch_loss=1.2e+4] \n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=89/100, avg_epoch_loss=1.01e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s, epoch=90/100, avg_epoch_loss=8.71e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.46it/s, epoch=91/100, avg_epoch_loss=9.1e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=92/100, avg_epoch_loss=8.23e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.36it/s, epoch=93/100, avg_epoch_loss=9.98e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=94/100, avg_epoch_loss=8.15e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.39it/s, epoch=95/100, avg_epoch_loss=9.04e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.39it/s, epoch=96/100, avg_epoch_loss=8.91e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=97/100, avg_epoch_loss=1.11e+4]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.44it/s, epoch=98/100, avg_epoch_loss=8.16e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=99/100, avg_epoch_loss=7.52e+3]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=100/100, avg_epoch_loss=6.77e+3]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF6daCEaLmF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation for all test data\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=dataset.test, \n",
        "    predictor=DF_predictor, \n",
        "    num_samples=100, \n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhEfosQxLomH",
        "colab_type": "code",
        "outputId": "a36e1e4e-3f49-4360-9f01-8ae08660cc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(dataset.test))\n",
        "\n",
        "print(json.dumps(agg_metrics, indent=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running evaluation: 100%|██████████| 2247/2247 [00:00<00:00, 45801.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"MSE\": 18876499.804294366,\n",
            "    \"abs_error\": 31932658.630607605,\n",
            "    \"abs_target_sum\": 128632956.0,\n",
            "    \"abs_target_mean\": 2385.272140631948,\n",
            "    \"seasonal_error\": 189.4933819611677,\n",
            "    \"MASE\": 2.5504296674374847,\n",
            "    \"MAPE\": 0.3804413659421475,\n",
            "    \"sMAPE\": 0.2775985060632508,\n",
            "    \"OWA\": NaN,\n",
            "    \"MSIS\": 71.7191248409653,\n",
            "    \"QuantileLoss[0.1]\": 38076520.64631615,\n",
            "    \"Coverage[0.1]\": 0.40097908322207443,\n",
            "    \"QuantileLoss[0.5]\": 31932658.567898393,\n",
            "    \"Coverage[0.5]\": 0.5643635959056528,\n",
            "    \"QuantileLoss[0.9]\": 22974524.90050087,\n",
            "    \"Coverage[0.9]\": 0.693072244474113,\n",
            "    \"RMSE\": 4344.709403895083,\n",
            "    \"NRMSE\": 1.8214732524163917,\n",
            "    \"ND\": 0.24824632523105203,\n",
            "    \"wQuantileLoss[0.1]\": 0.29600906198809696,\n",
            "    \"wQuantileLoss[0.5]\": 0.248246324743547,\n",
            "    \"wQuantileLoss[0.9]\": 0.17860527826555483,\n",
            "    \"mean_wQuantileLoss\": 0.24095355499906626,\n",
            "    \"MAE_Coverage\": 0.19075681155120475\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRUsFh_gRQUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax8L0q6fV_FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J5SRoyOcCcs",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Define Custom Estimator\n",
        "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
        "# You may not use this file except in compliance with the License.\n",
        "# A copy of the License is located at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# or in the \"license\" file accompanying this file. This file is distributed\n",
        "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
        "# express or implied. See the License for the specific language governing\n",
        "# permissions and limitations under the License.\n",
        "\n",
        "# Standard library imports\n",
        "from typing import List, Optional\n",
        "\n",
        "# First-party imports\n",
        "from gluonts import transform\n",
        "from gluonts.block.feature import FeatureEmbedder\n",
        "from gluonts.core.component import validated\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.distribution import DistributionOutput, StudentTOutput\n",
        "\n",
        "from gluonts.model.deep_factor.RNNModel import RNNModel\n",
        "from gluonts.model.deep_factor._network import (\n",
        "    DeepFactorTrainingNetwork,\n",
        "    DeepFactorPredictionNetwork,\n",
        ")\n",
        "from gluonts.model.estimator import GluonEstimator\n",
        "from gluonts.model.predictor import Predictor, RepresentableBlockPredictor\n",
        "from gluonts.time_feature import time_features_from_frequency_str\n",
        "from gluonts.trainer import Trainer\n",
        "from gluonts.transform import (\n",
        "    AddTimeFeatures,\n",
        "    AsNumpyArray,\n",
        "    Chain,\n",
        "    SetFieldIfNotPresent,\n",
        "    TestSplitSampler,\n",
        "    Transformation,\n",
        ")\n",
        "\n",
        "\n",
        "# Third-party imports\n",
        "\n",
        "\n",
        "class custom_DeepFactorEstimator(GluonEstimator):\n",
        "    r\"\"\"\n",
        "    DeepFactorEstimator is an implementation of the 2019 ICML paper \"Deep Factors for Forecasting\"\n",
        "    https://arxiv.org/abs/1905.12417.  It uses a global RNN model to learn patterns across multiple related time series\n",
        "    and an arbitrary local model to model the time series on a per time series basis.  In the current implementation,\n",
        "    the local model is a RNN (DF-RNN).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq\n",
        "        Time series frequency.\n",
        "    prediction_length\n",
        "        Prediction length.\n",
        "    num_hidden_global\n",
        "        Number of units per hidden layer for the global RNN model (default: 50).\n",
        "    num_layers_global\n",
        "        Number of hidden layers for the global RNN model (default: 1).\n",
        "    num_factors\n",
        "        Number of global factors (default: 10).\n",
        "    num_hidden_local\n",
        "        Number of units per hidden layer for the local RNN model (default: 5).\n",
        "    num_layers_local\n",
        "        Number of hidden layers for the global local model (default: 1).\n",
        "    cell_type\n",
        "        Type of recurrent cells to use (available: 'lstm' or 'gru';\n",
        "        default: 'lstm').\n",
        "    trainer\n",
        "        Trainer object to be used (default: Trainer()).\n",
        "    context_length\n",
        "        Training length (default: None, in which case context_length = prediction_length).\n",
        "    num_parallel_samples\n",
        "        Number of evaluation samples per time series to increase parallelism during inference.\n",
        "        This is a model optimization that does not affect the accuracy (default: 100).\n",
        "    cardinality\n",
        "        List consisting of the number of time series (default: list([1]).\n",
        "    embedding_dimension\n",
        "        Dimension of the embeddings for categorical features (the same\n",
        "        dimension is used for all embeddings, default: 10).\n",
        "    distr_output\n",
        "        Distribution to use to evaluate observations and sample predictions\n",
        "        (default: StudentTOutput()).\n",
        "    \"\"\"\n",
        "\n",
        "    @validated()\n",
        "    def __init__(\n",
        "        self,\n",
        "        freq: str,\n",
        "        prediction_length: int,\n",
        "        num_hidden_global: int = 50,\n",
        "        num_layers_global: int = 1,\n",
        "        num_factors: int = 10,\n",
        "        num_hidden_local: int = 5,\n",
        "        num_layers_local: int = 1,\n",
        "        cell_type: str = \"lstm\",\n",
        "        trainer: Trainer = Trainer(),\n",
        "        context_length: Optional[int] = None,\n",
        "        num_parallel_samples: int = 100,\n",
        "        cardinality: List[int] = list([1]),\n",
        "        embedding_dimension: int = 10,\n",
        "        distr_output: DistributionOutput = StudentTOutput(),\n",
        "    ) -> None:\n",
        "        super().__init__(trainer=trainer)\n",
        "\n",
        "        assert (\n",
        "            prediction_length > 0\n",
        "        ), \"The value of `prediction_length` should be > 0\"\n",
        "        assert (\n",
        "            context_length is None or context_length > 0\n",
        "        ), \"The value of `context_length` should be > 0\"\n",
        "        assert num_layers_global > 0, \"The value of `num_layers` should be > 0\"\n",
        "        assert num_hidden_global > 0, \"The value of `num_hidden` should be > 0\"\n",
        "        assert num_factors > 0, \"The value of `num_factors` should be > 0\"\n",
        "        assert (\n",
        "            num_hidden_local > 0\n",
        "        ), \"The value of `num_hidden_local` should be > 0\"\n",
        "        assert (\n",
        "            num_layers_local > 0\n",
        "        ), \"The value of `num_layers_local` should be > 0\"\n",
        "        assert all(\n",
        "            [c > 0 for c in cardinality]\n",
        "        ), \"Elements of `cardinality` should be > 0\"\n",
        "        assert (\n",
        "            embedding_dimension > 0\n",
        "        ), \"The value of `embedding_dimension` should be > 0\"\n",
        "        assert (\n",
        "            num_parallel_samples > 0\n",
        "        ), \"The value of `num_parallel_samples` should be > 0\"\n",
        "\n",
        "        self.freq = freq\n",
        "        self.context_length = (\n",
        "            context_length if context_length is not None else prediction_length\n",
        "        )\n",
        "        self.prediction_length = prediction_length\n",
        "        self.distr_output = distr_output\n",
        "        self.num_parallel_samples = num_parallel_samples\n",
        "        self.cardinality = cardinality\n",
        "        self.embedding_dimensions = [embedding_dimension for _ in cardinality]\n",
        "\n",
        "        self.global_model = RNNModel(\n",
        "            mode=cell_type,\n",
        "            num_hidden=num_hidden_global,\n",
        "            num_layers=num_layers_global,\n",
        "            num_output=num_factors,\n",
        "        )\n",
        "\n",
        "        # TODO: Allow the local model to be defined as an arbitrary local model, e.g. DF-GP and DF-LDS\n",
        "        self.local_model = RNNModel(\n",
        "            mode=cell_type,\n",
        "            num_hidden=num_hidden_local,\n",
        "            num_layers=num_layers_local,\n",
        "            num_output=1,\n",
        "        )\n",
        "\n",
        "    def create_transformation(self) -> Transformation:\n",
        "        return Chain(\n",
        "            trans=[\n",
        "                AsNumpyArray(field=FieldName.TARGET, expected_ndim=1),\n",
        "                AddObservedValuesIndicator(\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    output_field=FieldName.OBSERVED_VALUES,\n",
        "                    dummy_value=self.distr_output.value_in_support,\n",
        "                    dtype=self.dtype,\n",
        "                ),\n",
        "                AddTimeFeatures(\n",
        "                    start_field=FieldName.START,\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    output_field=FieldName.FEAT_TIME,\n",
        "                    time_features=time_features_from_frequency_str(self.freq),\n",
        "                    pred_length=self.prediction_length,\n",
        "                ),\n",
        "                AddAgeFeature(\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    output_field=FieldName.FEAT_AGE,\n",
        "                    pred_length=self.prediction_length,\n",
        "                    log_scale=True,\n",
        "                    dtype=self.dtype,\n",
        "                ),\n",
        "                VstackFeatures(\n",
        "                    output_field=FieldName.FEAT_TIME,\n",
        "                    input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
        "                ),\n",
        "                SetFieldIfNotPresent(\n",
        "                    field=FieldName.FEAT_STATIC_CAT, value=[0.0]\n",
        "                ),\n",
        "                AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\n",
        "                transform.InstanceSplitter(\n",
        "                    target_field=FieldName.TARGET,\n",
        "                    is_pad_field=FieldName.IS_PAD,\n",
        "                    start_field=FieldName.START,\n",
        "                    forecast_start_field=FieldName.FORECAST_START,\n",
        "                    train_sampler=TestSplitSampler(),\n",
        "                    time_series_fields=[\n",
        "                        FieldName.FEAT_TIME,\n",
        "                        FieldName.OBSERVED_VALUES,\n",
        "                    ],\n",
        "                    past_length=self.context_length,\n",
        "                    future_length=self.prediction_length,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def create_training_network(self) -> DeepFactorTrainingNetwork:\n",
        "        return DeepFactorTrainingNetwork(\n",
        "            embedder=FeatureEmbedder(\n",
        "                cardinalities=self.cardinality,\n",
        "                embedding_dims=self.embedding_dimensions,\n",
        "            ),\n",
        "            global_model=self.global_model,\n",
        "            local_model=self.local_model,\n",
        "        )\n",
        "\n",
        "    def create_predictor(\n",
        "        self,\n",
        "        transformation: Transformation,\n",
        "        trained_network: DeepFactorTrainingNetwork,\n",
        "    ) -> Predictor:\n",
        "        prediction_net = DeepFactorPredictionNetwork(\n",
        "            embedder=trained_network.embedder,\n",
        "            global_model=trained_network.global_model,\n",
        "            local_model=trained_network.local_model,\n",
        "            prediction_len=self.prediction_length,\n",
        "            num_parallel_samples=self.num_parallel_samples,\n",
        "            params=trained_network.collect_params(),\n",
        "        )\n",
        "\n",
        "        return RepresentableBlockPredictor(\n",
        "            input_transform=transformation,\n",
        "            prediction_net=prediction_net,\n",
        "            batch_size=self.trainer.batch_size,\n",
        "            freq=self.freq,\n",
        "            prediction_length=self.prediction_length,\n",
        "            ctx=self.trainer.ctx,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv1nqZCxVj_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gluon-ts.mxnet.io/api/gluonts/gluonts.model.deep_factor.html\n",
        "DF_estimator = custom_DeepFactorEstimator(\n",
        "    freq=dataset.metadata.freq, # Time series frequency\n",
        "    prediction_length=dataset.metadata.prediction_length, # Prediction length.\n",
        "    num_hidden_global=50, # (default: 50).\n",
        "    num_layers_global=1, # (default: 1).\n",
        "    num_factors=10, # (default: 10).\n",
        "    num_hidden_local=5, # (default: 5).\n",
        "    num_layers_local=1, # (default: 1).\n",
        "    cell_type='lstm', # (default: ‘lstm’).\n",
        "    trainer = deepfactor_trainer, # (default: Trainer()).\n",
        "    context_length=168, # (default: None, in which case context_length = prediction_length).\n",
        "    num_parallel_samples=100, # (default: 100).\n",
        "    cardinality=[int(dataset.metadata.feat_static_cat[0].cardinality)], # (default: list([1]).\n",
        "    embedding_dimension=10, # (default: 10).\n",
        "    #distr_output=StudentTOutput(), # (default: StudentTOutput()).\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "77d78e7a-c146-4fe1-fec8-9330b0535517",
        "id": "0QPStOQXf0ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DF_predictor = DF_estimator.train(dataset.train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:14<00:00,  3.52it/s, epoch=1/100, avg_epoch_loss=3.21e+7]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.24it/s, epoch=2/100, avg_epoch_loss=1.68e+7]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.31it/s, epoch=3/100, avg_epoch_loss=1.32e+7]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.76it/s, epoch=4/100, avg_epoch_loss=8.78e+6]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.74it/s, epoch=5/100, avg_epoch_loss=5.99e+6]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.74it/s, epoch=6/100, avg_epoch_loss=3.33e+6]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.78it/s, epoch=7/100, avg_epoch_loss=2.73e+6]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.75it/s, epoch=8/100, avg_epoch_loss=1.03e+6]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.71it/s, epoch=9/100, avg_epoch_loss=6.87e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.65it/s, epoch=10/100, avg_epoch_loss=5.21e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.72it/s, epoch=11/100, avg_epoch_loss=4.86e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.71it/s, epoch=12/100, avg_epoch_loss=4.25e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.76it/s, epoch=13/100, avg_epoch_loss=3.48e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.74it/s, epoch=14/100, avg_epoch_loss=2.97e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.69it/s, epoch=15/100, avg_epoch_loss=3.51e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.73it/s, epoch=16/100, avg_epoch_loss=2.07e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.74it/s, epoch=17/100, avg_epoch_loss=1.99e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.78it/s, epoch=18/100, avg_epoch_loss=1.86e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.79it/s, epoch=19/100, avg_epoch_loss=2.04e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.77it/s, epoch=20/100, avg_epoch_loss=1.48e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.73it/s, epoch=21/100, avg_epoch_loss=2.43e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.82it/s, epoch=22/100, avg_epoch_loss=1.78e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.82it/s, epoch=23/100, avg_epoch_loss=1.42e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.79it/s, epoch=24/100, avg_epoch_loss=1.28e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.84it/s, epoch=25/100, avg_epoch_loss=1.34e+5]\n",
            "100%|██████████| 50/50 [00:12<00:00,  3.85it/s, epoch=26/100, avg_epoch_loss=9.69e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.83it/s, epoch=27/100, avg_epoch_loss=9.51e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.80it/s, epoch=28/100, avg_epoch_loss=1.01e+5]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.80it/s, epoch=29/100, avg_epoch_loss=8.35e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.82it/s, epoch=30/100, avg_epoch_loss=9.96e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.80it/s, epoch=31/100, avg_epoch_loss=7.47e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.73it/s, epoch=32/100, avg_epoch_loss=7.57e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.62it/s, epoch=33/100, avg_epoch_loss=6.65e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.69it/s, epoch=34/100, avg_epoch_loss=8.74e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.69it/s, epoch=35/100, avg_epoch_loss=6.19e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.68it/s, epoch=36/100, avg_epoch_loss=6.98e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.66it/s, epoch=37/100, avg_epoch_loss=5.5e+4] \n",
            "100%|██████████| 50/50 [00:13<00:00,  3.72it/s, epoch=38/100, avg_epoch_loss=5.52e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.73it/s, epoch=39/100, avg_epoch_loss=5.41e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.64it/s, epoch=40/100, avg_epoch_loss=4.53e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.61it/s, epoch=41/100, avg_epoch_loss=5.23e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.68it/s, epoch=42/100, avg_epoch_loss=4.47e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.76it/s, epoch=43/100, avg_epoch_loss=4.71e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.63it/s, epoch=44/100, avg_epoch_loss=3.87e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.65it/s, epoch=45/100, avg_epoch_loss=4.5e+4] \n",
            "100%|██████████| 50/50 [00:13<00:00,  3.73it/s, epoch=46/100, avg_epoch_loss=3.89e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.70it/s, epoch=47/100, avg_epoch_loss=3.83e+4]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.04it/s, epoch=48/100, avg_epoch_loss=3.66e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.65it/s, epoch=49/100, avg_epoch_loss=3.27e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.54it/s, epoch=50/100, avg_epoch_loss=3.13e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.48it/s, epoch=51/100, avg_epoch_loss=3.48e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.49it/s, epoch=52/100, avg_epoch_loss=3.11e+4]\n",
            "100%|██████████| 50/50 [00:13<00:00,  3.58it/s, epoch=53/100, avg_epoch_loss=3.62e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.50it/s, epoch=54/100, avg_epoch_loss=3.04e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.47it/s, epoch=55/100, avg_epoch_loss=3.46e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.49it/s, epoch=56/100, avg_epoch_loss=3.19e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.45it/s, epoch=57/100, avg_epoch_loss=2.98e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.42it/s, epoch=58/100, avg_epoch_loss=2.71e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.38it/s, epoch=59/100, avg_epoch_loss=2.24e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.40it/s, epoch=60/100, avg_epoch_loss=2.55e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.35it/s, epoch=61/100, avg_epoch_loss=2.27e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.34it/s, epoch=62/100, avg_epoch_loss=2.05e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.29it/s, epoch=63/100, avg_epoch_loss=2.58e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.32it/s, epoch=64/100, avg_epoch_loss=2.32e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.35it/s, epoch=65/100, avg_epoch_loss=2.07e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.24it/s, epoch=66/100, avg_epoch_loss=1.68e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.29it/s, epoch=67/100, avg_epoch_loss=2.02e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.29it/s, epoch=68/100, avg_epoch_loss=1.93e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.27it/s, epoch=69/100, avg_epoch_loss=2.28e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.30it/s, epoch=70/100, avg_epoch_loss=1.87e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.26it/s, epoch=71/100, avg_epoch_loss=1.85e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.26it/s, epoch=72/100, avg_epoch_loss=2.09e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.32it/s, epoch=73/100, avg_epoch_loss=1.62e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.27it/s, epoch=74/100, avg_epoch_loss=2.04e+4]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.28it/s, epoch=75/100, avg_epoch_loss=1.88e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=76/100, avg_epoch_loss=1.81e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=77/100, avg_epoch_loss=1.59e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=78/100, avg_epoch_loss=2.11e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=79/100, avg_epoch_loss=1.48e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=80/100, avg_epoch_loss=1.54e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=81/100, avg_epoch_loss=1.3e+4] \n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=82/100, avg_epoch_loss=1.38e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=83/100, avg_epoch_loss=1.66e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=84/100, avg_epoch_loss=1.27e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=85/100, avg_epoch_loss=1.52e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=86/100, avg_epoch_loss=1.24e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.34it/s, epoch=87/100, avg_epoch_loss=1.24e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=88/100, avg_epoch_loss=1.13e+4]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.81it/s, epoch=89/100, avg_epoch_loss=1.14e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=90/100, avg_epoch_loss=1.17e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=91/100, avg_epoch_loss=1.02e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=92/100, avg_epoch_loss=1.06e+4]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=93/100, avg_epoch_loss=1e+4]   \n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, epoch=94/100, avg_epoch_loss=9.52e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=95/100, avg_epoch_loss=9.67e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=96/100, avg_epoch_loss=8.9e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=97/100, avg_epoch_loss=9.51e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=98/100, avg_epoch_loss=8.79e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=99/100, avg_epoch_loss=8.77e+3]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.37it/s, epoch=100/100, avg_epoch_loss=8.19e+3]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "02903d35-c5e6-44e8-c1a8-4bfab86c34b7",
        "id": "aTn9wIECf0km",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "# Evaluation for all test data\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=dataset.test, \n",
        "    predictor=DF_predictor, \n",
        "    num_samples=100, \n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
        "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(dataset.test))\n",
        "\n",
        "print(json.dumps(agg_metrics, indent=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running evaluation: 100%|██████████| 2247/2247 [00:00<00:00, 39655.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"MSE\": 21318475.439580247,\n",
            "    \"abs_error\": 31645725.93480301,\n",
            "    \"abs_target_sum\": 128632956.0,\n",
            "    \"abs_target_mean\": 2385.272140631948,\n",
            "    \"seasonal_error\": 189.4933819611677,\n",
            "    \"MASE\": 2.4330016020356733,\n",
            "    \"MAPE\": 0.33228281572004065,\n",
            "    \"sMAPE\": 0.26993763528768305,\n",
            "    \"OWA\": NaN,\n",
            "    \"MSIS\": 67.34964659011494,\n",
            "    \"QuantileLoss[0.1]\": 22104872.01756821,\n",
            "    \"Coverage[0.1]\": 0.26717104287197724,\n",
            "    \"QuantileLoss[0.5]\": 31645726.060558725,\n",
            "    \"Coverage[0.5]\": 0.41492360183948973,\n",
            "    \"QuantileLoss[0.9]\": 38415444.580503464,\n",
            "    \"Coverage[0.9]\": 0.5692404687731789,\n",
            "    \"RMSE\": 4617.193459189278,\n",
            "    \"NRMSE\": 1.9357092972905015,\n",
            "    \"ND\": 0.24601569394707068,\n",
            "    \"wQuantileLoss[0.1]\": 0.1718445467238443,\n",
            "    \"wQuantileLoss[0.5]\": 0.24601569492470285,\n",
            "    \"wQuantileLoss[0.9]\": 0.2986438761502415,\n",
            "    \"mean_wQuantileLoss\": 0.23883470593292958,\n",
            "    \"MAE_Coverage\": 0.19433565741976955\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5khNgmBVj8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}